#!/usr/bin/env python3
"""
ç®€åŒ–çš„BERT + TIMæµ‹è¯•è„šæœ¬
æµ‹è¯•åŸºæœ¬åŠŸèƒ½æ˜¯å¦æ­£å¸¸
"""

from bert_sentiment_analysis import BertTimExperiment, get_bert_model_configs


def test_basic_functionality():
    """æµ‹è¯•åŸºæœ¬åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•BERT + TIMåŸºæœ¬åŠŸèƒ½")
    print("=" * 50)

    # æ˜¾ç¤ºå¯ç”¨æ¨¡å‹
    configs = get_bert_model_configs()
    print("ğŸ“‹ å¯ç”¨æ¨¡å‹:")
    for name, config in configs.items():
        print(f"  â€¢ {name}: {config['description']}")
    print()

    # åˆ›å»ºå°å‹å®éªŒå®ä¾‹ (æ›´å°‘æ ·æœ¬)
    experiment = BertTimExperiment(
        dataset_name="imdb",
        train_count=50,  # éå¸¸å°çš„æ•°æ®é›†ç”¨äºæµ‹è¯•
        valid_count=20,
        test_count=20,
        random_state=42,
        output_dir="./test_results",
    )

    print("ğŸ”„ æµ‹è¯•æ•°æ®åŠ è½½...")
    try:
        data = experiment.prepare_data()
        print("âœ… æ•°æ®åŠ è½½æˆåŠŸ")
        x_train, y_train, x_valid, y_valid, x_test, y_test = data
        print(f"   è®­ç»ƒæ•°æ®ç±»å‹: {type(x_train)}, é•¿åº¦: {len(x_train)}")
        print(f"   æ ‡ç­¾ç±»å‹: {type(y_train)}, å½¢çŠ¶: {y_train.shape}")

        # æµ‹è¯•å•ä¸ªæ¨¡å‹åˆ›å»º (ä¸è¿è¡Œå®Œæ•´å®éªŒ)
        print("\nğŸ¤– æµ‹è¯•æ¨¡å‹åˆ›å»º...")
        model_config = configs["distilbert-base-uncased"]
        model = experiment.create_bert_model(model_config)
        print("âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        print(f"   æ¨¡å‹ç±»å‹: {type(model)}")

        print("\nâš™ï¸ æµ‹è¯•TIMè¯„ä¼°å™¨è®¾ç½®...")
        tim_evaluator = experiment.setup_tim_evaluator(
            t1=0, t2=None, num_epochs=1, batch_size=4
        )
        print("âœ… TIMè¯„ä¼°å™¨åˆ›å»ºæˆåŠŸ")
        print(f"   è¯„ä¼°å™¨ç±»å‹: {type(tim_evaluator)}")

        print("\nğŸ“Š æµ‹è¯•TIMæ•°æ®è¾“å…¥...")
        # æµ‹è¯•tokenizationå’Œæ•°æ®è½¬æ¢
        print("   ğŸ”„ å¯¹æ–‡æœ¬æ•°æ®è¿›è¡Œtokenization...")

        train_dataset = model.tokenize(x_train)
        valid_dataset = model.tokenize(x_valid)

        # è·å–tokenizedçš„tensoræ•°æ®
        train_input_ids = train_dataset.tensors[0]
        train_attention_mask = train_dataset.tensors[1]
        valid_input_ids = valid_dataset.tensors[0]
        _ = valid_dataset.tensors[1]

        print(f"   Tokenizedæ•°æ®å½¢çŠ¶: {train_input_ids.shape}")

        # ä¸ºTIMåˆ›å»ºtensorè¾“å…¥
        tim_evaluator.input_data(
            x_train=train_input_ids,
            y_train=y_train,
            x_valid=valid_input_ids,
            y_valid=y_valid,
        )
        print("âœ… TIMæ•°æ®è¾“å…¥æˆåŠŸ")
        print(f"   TIMè®­ç»ƒæ ·æœ¬æ•°: {tim_evaluator.num_points}")

        # åˆ›å»ºBERTåŒ…è£…å™¨
        import torch

        class BertTimWrapper(torch.nn.Module):
            def __init__(self, bert_model, attention_mask):
                super().__init__()
                self.bert_model = bert_model
                self.attention_mask = attention_mask

            def forward(self, input_ids):
                batch_size = input_ids.shape[0]
                mask = self.attention_mask[:batch_size]
                return self.bert_model(input_ids, attention_mask=mask)

            def predict(self, input_ids):
                return self.forward(input_ids)

            def parameters(self):
                return self.bert_model.parameters()

            def named_parameters(self):
                return self.bert_model.named_parameters()

            def zero_grad(self):
                return self.bert_model.zero_grad()

        bert_wrapper = BertTimWrapper(model, train_attention_mask)
        tim_evaluator.pred_model = bert_wrapper
        print("âœ… TIM BERTåŒ…è£…å™¨è®¾ç½®æˆåŠŸ")

        return True

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = test_basic_functionality()
    if success:
        print("\nğŸ‰ åŸºæœ¬åŠŸèƒ½æµ‹è¯•é€šè¿‡! ")
        print("ç°åœ¨å¯ä»¥è¿è¡Œå®Œæ•´å®éªŒ: python my_experiments/bert_sentiment_analysis.py")
    else:
        print("\nğŸ’¥ åŸºæœ¬åŠŸèƒ½æµ‹è¯•å¤±è´¥")
        print("éœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")
