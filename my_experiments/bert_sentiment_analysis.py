"""
BERTæƒ…æ„Ÿåˆ†æå®éªŒ - ä½¿ç”¨OpenDataVal TIMæ–¹æ³•

ä½¿ç”¨Time-varying Influence Measurement (TIM)è¿›è¡ŒBERTæƒ…æ„Ÿåˆ†æå¾®è°ƒçš„æ•°æ®ä»·å€¼è¯„ä¼°å®éªŒã€‚
æœ¬å®éªŒè®¾ç½® t1 = 0, t2 = Tï¼ˆå®Œæ•´è®­ç»ƒè¿‡ç¨‹ï¼‰ï¼Œä½¿ç”¨ä¸åŒå¤§å°çš„BERTæ¨¡å‹è¿›è¡Œæ¯”è¾ƒã€‚

å®éªŒé…ç½®ï¼š
- æ•°æ®é›†: IMDBç”µå½±è¯„è®ºæƒ…æ„Ÿåˆ†ææ•°æ®é›†
- æ¨¡å‹: å¤šç§BERTæ¨¡å‹å¤§å°é€‰é¡¹ï¼ˆä»DistilBERTåˆ°BERT-Largeï¼‰
- è¯„ä¼°æ–¹æ³•: TIM (Time-varying Influence Measurement)
- æ—¶é—´çª—å£: [0, T] - å®Œæ•´è®­ç»ƒè¿‡ç¨‹
"""

from pathlib import Path
from typing import Dict, List, Tuple

import numpy as np
import torch

from opendataval.dataloader import DataFetcher
from opendataval.dataval.tim import TimInfluence
from opendataval.model import BertClassifier


def get_bert_model_configs() -> Dict[str, Dict]:
    """è·å–ä¸åŒå¤§å°çš„BERTæ¨¡å‹é…ç½®

    è¿”å›ä»å°åˆ°å¤§çš„BERTæ¨¡å‹é…ç½®åˆ—è¡¨ï¼ŒåŒ…æ‹¬å‚æ•°è§„æ¨¡ä¿¡æ¯ã€‚

    Returns:
        Dict[str, Dict]: æ¨¡å‹é…ç½®å­—å…¸ï¼Œé”®ä¸ºæ¨¡å‹åç§°ï¼Œå€¼ä¸ºé…ç½®å‚æ•°
    """
    return {
        # å°å‹æ¨¡å‹ (é€‚åˆå¿«é€Ÿå®éªŒ)
        "distilbert-base-uncased": {
            "pretrained_model_name": "distilbert-base-uncased",
            "parameters": "66M",
            "description": "DistilBERT-Base (66Må‚æ•°) - BERTçš„è½»é‡çº§ç‰ˆæœ¬ï¼Œé€Ÿåº¦å¿«",
        },
        # æ ‡å‡†BERTæ¨¡å‹
        "bert-base-uncased": {
            "pretrained_model_name": "bert-base-uncased",
            "parameters": "110M",
            "description": "BERT-Base (110Må‚æ•°) - åŸå§‹BERTåŸºç¡€ç‰ˆæœ¬",
        },
        "bert-base-cased": {
            "pretrained_model_name": "bert-base-cased",
            "parameters": "110M",
            "description": "BERT-Base-Cased (110Må‚æ•°) - åŒºåˆ†å¤§å°å†™ç‰ˆæœ¬",
        },
        # å¤§å‹æ¨¡å‹ (æ¨èç”¨äºæœ€ä½³æ€§èƒ½)
        "bert-large-uncased": {
            "pretrained_model_name": "bert-large-uncased",
            "parameters": "340M",
            "description": "BERT-Large (340Må‚æ•°) - æœ€å¤§çš„æ ‡å‡†BERTæ¨¡å‹ï¼Œæ€§èƒ½æœ€ä½³",
        },
        "bert-large-cased": {
            "pretrained_model_name": "bert-large-cased",
            "parameters": "340M",
            "description": "BERT-Large-Cased (340Må‚æ•°) - å¤§å‹åŒºåˆ†å¤§å°å†™ç‰ˆæœ¬",
        },
        # RoBERTaå˜ä½“ (é€šå¸¸æ€§èƒ½æ›´å¥½)
        "roberta-base": {
            "pretrained_model_name": "roberta-base",
            "parameters": "125M",
            "description": "RoBERTa-Base (125Må‚æ•°) - BERTçš„æ”¹è¿›ç‰ˆæœ¬",
        },
        "roberta-large": {
            "pretrained_model_name": "roberta-large",
            "parameters": "355M",
            "description": "RoBERTa-Large (355Må‚æ•°) - å¤§å‹RoBERTaæ¨¡å‹ï¼Œé€šå¸¸æ€§èƒ½æœ€ä½³",
        },
    }


class BertTimExperiment:
    """BERT + TIM æƒ…æ„Ÿåˆ†æå®éªŒç±»"""

    def __init__(
        self,
        dataset_name: str = "imdb",
        train_count: int = 1000,
        valid_count: int = 200,
        test_count: int = 200,
        random_state: int = 42,
        output_dir: str = "./results",
    ):
        """
        åˆå§‹åŒ–å®éªŒé…ç½®

        Parameters:
        -----------
        dataset_name : str
            æ•°æ®é›†åç§°ï¼Œé»˜è®¤"imdb"ç”¨äºæƒ…æ„Ÿåˆ†æ
        train_count : int
            è®­ç»ƒæ ·æœ¬æ•°é‡
        valid_count : int
            éªŒè¯æ ·æœ¬æ•°é‡
        test_count : int
            æµ‹è¯•æ ·æœ¬æ•°é‡
        random_state : int
            éšæœºç§å­
        output_dir : str
            ç»“æœè¾“å‡ºç›®å½•
        """
        self.dataset_name = dataset_name
        self.train_count = train_count
        self.valid_count = valid_count
        self.test_count = test_count
        self.random_state = random_state
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # è®¾ç½®éšæœºç§å­
        torch.manual_seed(random_state)
        np.random.seed(random_state)

        # å®éªŒç»“æœå­˜å‚¨
        self.results = {}

    def prepare_data(
        self,
    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:
        """å‡†å¤‡IMDBæƒ…æ„Ÿåˆ†ææ•°æ®"""
        print(f"ğŸ”„ åŠ è½½æ•°æ®é›†: {self.dataset_name}")
        print(
            f"ğŸ“Š æ•°æ®è§„æ¨¡: è®­ç»ƒ={self.train_count}, éªŒè¯={self.valid_count}, æµ‹è¯•={self.test_count}"
        )

        # ä½¿ç”¨DataFetcheråŠ è½½IMDBæ•°æ®é›†
        fetcher = DataFetcher(
            dataset_name=self.dataset_name,
            train_count=self.train_count,
            valid_count=self.valid_count,
            test_count=self.test_count,
            random_state=self.random_state,
        )

        # è·å–åŸå§‹æ–‡æœ¬æ•°æ®ï¼ˆä¸ä½¿ç”¨embeddingï¼‰
        x_train, y_train, x_valid, y_valid, x_test, y_test = fetcher.datapoints

        print("âœ… æ•°æ®åŠ è½½å®Œæˆ")
        print(f"   è®­ç»ƒé›†æ ·æœ¬æ•°: {len(x_train)}")
        print(f"   éªŒè¯é›†æ ·æœ¬æ•°: {len(x_valid)}")
        print(f"   æµ‹è¯•é›†æ ·æœ¬æ•°: {len(x_test)}")
        print(f"   ç±»åˆ«æ•°: {len(np.unique(y_train))}")

        return x_train, y_train, x_valid, y_valid, x_test, y_test

    def create_bert_model(self, model_config: Dict) -> BertClassifier:
        """åˆ›å»ºBERTåˆ†ç±»å™¨æ¨¡å‹"""
        model = BertClassifier(
            pretrained_model_name=model_config["pretrained_model_name"],
            num_classes=2,  # äºŒåˆ†ç±»æƒ…æ„Ÿåˆ†æ
            dropout_rate=0.2,
            num_train_layers=2,  # å¾®è°ƒæœ€å2å±‚
        )

        # å¦‚æœGPUå¯ç”¨ï¼Œå°†æ¨¡å‹ç§»åˆ°GPU
        device = torch.device(
            "cuda"
            if torch.cuda.is_available()
            else "mps"
            if torch.backends.mps.is_available()
            else "cpu"
        )
        model = model.to(device)

        print(f"ğŸ¤– åˆ›å»ºæ¨¡å‹: {model_config['description']}")
        print(f"ğŸ“ è®¾å¤‡: {device}")

        return model

    def setup_tim_evaluator(
        self, t1: int = 0, t2: int = None, num_epochs: int = 5, batch_size: int = 16
    ) -> TimInfluence:
        """
        è®¾ç½®TIMè¯„ä¼°å™¨

        Parameters:
        -----------
        t1 : int
            æ—¶é—´çª—å£å¼€å§‹æ­¥éª¤ï¼Œé»˜è®¤0ï¼ˆä»å¼€å§‹ï¼‰
        t2 : int
            æ—¶é—´çª—å£ç»“æŸæ­¥éª¤ï¼ŒNoneè¡¨ç¤ºåˆ°ç»“æŸï¼ˆTï¼‰
        num_epochs : int
            è®­ç»ƒè½®æ•°
        batch_size : int
            æ‰¹å¤„ç†å¤§å°
        """
        print("âš™ï¸  è®¾ç½®TIMè¯„ä¼°å™¨")
        print(f"   æ—¶é—´çª—å£: t1={t1}, t2={'T(end)' if t2 is None else t2}")
        print(f"   è®­ç»ƒé…ç½®: epochs={num_epochs}, batch_size={batch_size}")

        tim_evaluator = TimInfluence(
            start_step=t1,
            end_step=t2,
            time_window_type="full" if t1 == 0 and t2 is None else "custom_range",
            num_epochs=num_epochs,
            batch_size=batch_size,
            regularization=0.01,
            finite_diff_eps=1e-5,
            random_state=self.random_state,
        )

        return tim_evaluator

    def run_single_experiment(
        self, model_name: str, model_config: Dict, data: Tuple, tim_config: Dict = None
    ) -> Dict:
        """è¿è¡Œå•ä¸ªBERT+TIMå®éªŒ"""
        x_train, y_train, x_valid, y_valid, x_test, y_test = data

        print("\n" + "=" * 60)
        print(f"ğŸ”¬ å¼€å§‹å®éªŒ: {model_name}")
        print(f"ğŸ“ {model_config['description']}")
        print("=" * 60)

        # é»˜è®¤TIMé…ç½®
        if tim_config is None:
            tim_config = {
                "t1": 0,
                "t2": None,  # åˆ°ç»“æŸ
                "num_epochs": 3,
                "batch_size": 8,  # BERTéœ€è¦è¾ƒå°çš„batch size
            }

        try:
            # 1. åˆ›å»ºæ¨¡å‹
            model = self.create_bert_model(model_config)

            # 2. è®¾ç½®TIMè¯„ä¼°å™¨
            tim_evaluator = self.setup_tim_evaluator(**tim_config)

            # 3. è¾“å…¥æ•°æ®åˆ°TIM
            tim_evaluator.input_data(
                x_train=x_train, y_train=y_train, x_valid=x_valid, y_valid=y_valid
            )

            # 4. è®¾ç½®é¢„æµ‹æ¨¡å‹
            tim_evaluator.pred_model = model

            # 5. è®­ç»ƒå¹¶è®°å½•çŠ¶æ€
            print("\nğŸš€ å¼€å§‹TIMè®­ç»ƒ...")
            tim_evaluator.train_data_values(
                epochs=tim_config["num_epochs"],
                batch_size=tim_config["batch_size"],
                lr=2e-5,  # BERTæ¨èå­¦ä¹ ç‡
            )

            # 6. è®¡ç®—å½±å“åŠ›æ•°æ®å€¼
            print("\nğŸ“Š è®¡ç®—æ•°æ®å½±å“åŠ›...")
            data_values = tim_evaluator.evaluate_data_values()

            # 7. åˆ†æç»“æœ
            results = self.analyze_results(
                model_name=model_name,
                data_values=data_values,
                tim_evaluator=tim_evaluator,
                y_train=y_train,
            )

            print(f"âœ… å®éªŒå®Œæˆ: {model_name}")
            return results

        except Exception as e:
            print(f"âŒ å®éªŒå¤±è´¥: {model_name}")
            print(f"   é”™è¯¯: {e!s}")
            return {"model_name": model_name, "status": "failed", "error": str(e)}

    def analyze_results(
        self,
        model_name: str,
        data_values: np.ndarray,
        tim_evaluator: TimInfluence,
        y_train: torch.Tensor,
    ) -> Dict:
        """åˆ†æTIMå®éªŒç»“æœ"""

        # åŸºç¡€ç»Ÿè®¡
        mean_influence = float(np.mean(data_values))
        std_influence = float(np.std(data_values))
        min_influence = float(np.min(data_values))
        max_influence = float(np.max(data_values))

        # æŒ‰ç±»åˆ«åˆ†æå½±å“åŠ›
        y_train_np = y_train.numpy() if isinstance(y_train, torch.Tensor) else y_train

        positive_indices = np.where(y_train_np == 1)[0]
        negative_indices = np.where(y_train_np == 0)[0]

        positive_influence = data_values[positive_indices]
        negative_influence = data_values[negative_indices]

        # æ‰¾å‡ºæœ€æœ‰å½±å“åŠ›çš„æ ·æœ¬
        top_k = 10
        most_influential_indices = np.argsort(data_values)[-top_k:][::-1]
        least_influential_indices = np.argsort(data_values)[:top_k]

        results = {
            "model_name": model_name,
            "status": "success",
            "data_values": data_values.tolist(),
            "statistics": {
                "mean_influence": mean_influence,
                "std_influence": std_influence,
                "min_influence": min_influence,
                "max_influence": max_influence,
                "total_samples": len(data_values),
            },
            "class_analysis": {
                "positive_samples": {
                    "count": len(positive_influence),
                    "mean_influence": float(np.mean(positive_influence)),
                    "std_influence": float(np.std(positive_influence)),
                },
                "negative_samples": {
                    "count": len(negative_influence),
                    "mean_influence": float(np.mean(negative_influence)),
                    "std_influence": float(np.std(negative_influence)),
                },
            },
            "top_influential": {
                "indices": most_influential_indices.tolist(),
                "values": data_values[most_influential_indices].tolist(),
            },
            "least_influential": {
                "indices": least_influential_indices.tolist(),
                "values": data_values[least_influential_indices].tolist(),
            },
            "training_info": {
                "total_steps": tim_evaluator.total_steps,
                "steps_per_epoch": tim_evaluator.steps_per_epoch,
                "cached_intervals": len(tim_evaluator._influence_cache),
            },
        }

        # æ‰“å°å…³é”®ç»“æœ
        print("\nğŸ“ˆ å®éªŒç»“æœæ‘˜è¦:")
        print(f"   å¹³å‡å½±å“åŠ›: {mean_influence:.6f}")
        print(f"   å½±å“åŠ›æ ‡å‡†å·®: {std_influence:.6f}")
        print(f"   å½±å“åŠ›èŒƒå›´: [{min_influence:.6f}, {max_influence:.6f}]")
        print(
            f"   æ­£é¢æ ·æœ¬å¹³å‡å½±å“åŠ›: {results['class_analysis']['positive_samples']['mean_influence']:.6f}"
        )
        print(
            f"   è´Ÿé¢æ ·æœ¬å¹³å‡å½±å“åŠ›: {results['class_analysis']['negative_samples']['mean_influence']:.6f}"
        )
        print(f"   è®­ç»ƒæ€»æ­¥æ•°: {tim_evaluator.total_steps}")

        return results

    def save_results(self, filename: str = None):
        """ä¿å­˜å®éªŒç»“æœåˆ°JSONæ–‡ä»¶"""
        import json

        if filename is None:
            filename = "bert_tim_experiment_results.json"

        filepath = self.output_dir / filename

        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)

        print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {filepath}")

    def run_full_experiment_suite(self, selected_models: List[str] = None):
        """è¿è¡Œå®Œæ•´çš„BERTæ¨¡å‹å¯¹æ¯”å®éªŒ"""

        print("ğŸ”¬ BERT + TIM æƒ…æ„Ÿåˆ†æå®éªŒå¥—ä»¶")
        print("=" * 80)

        # è·å–æ¨¡å‹é…ç½®
        model_configs = get_bert_model_configs()

        if selected_models is None:
            # é»˜è®¤é€‰æ‹©ä»å°åˆ°å¤§çš„å…³é”®æ¨¡å‹
            selected_models = [
                "distilbert-base-uncased",  # å°å‹: 66Må‚æ•°
                "bert-base-uncased",  # ä¸­å‹: 110Må‚æ•°
                "bert-large-uncased",  # å¤§å‹: 340Må‚æ•° (æœ€å¤§æ ‡å‡†BERT)
            ]

        print(f"ğŸ“‹ é€‰æ‹©çš„æ¨¡å‹: {selected_models}")

        # å‡†å¤‡æ•°æ®ï¼ˆæ‰€æœ‰å®éªŒä½¿ç”¨ç›¸åŒæ•°æ®ï¼‰
        data = self.prepare_data()

        # TIMé…ç½® - è®¾ç½® t1=0, t2=Tï¼ˆå®Œæ•´è®­ç»ƒè¿‡ç¨‹ï¼‰
        tim_config = {
            "t1": 0,  # ä»è®­ç»ƒå¼€å§‹
            "t2": None,  # åˆ°è®­ç»ƒç»“æŸï¼ˆTï¼‰
            "num_epochs": 2,  # å‡å°‘epochæ•°ä»¥é€‚åº”å®éªŒ
            "batch_size": 8,  # è¾ƒå°çš„batch sizeé€‚åˆBERT
        }

        print(
            f"âš™ï¸  TIMé…ç½®: t1={tim_config['t1']}, t2=T, epochs={tim_config['num_epochs']}"
        )

        # è¿è¡Œæ¯ä¸ªæ¨¡å‹çš„å®éªŒ
        for model_name in selected_models:
            if model_name not in model_configs:
                print(f"âš ï¸  è·³è¿‡æœªçŸ¥æ¨¡å‹: {model_name}")
                continue

            model_config = model_configs[model_name]

            # è¿è¡Œå®éªŒ
            result = self.run_single_experiment(
                model_name=model_name,
                model_config=model_config,
                data=data,
                tim_config=tim_config,
            )

            self.results[model_name] = result

        # ä¿å­˜ç»“æœ
        self.save_results()

        # æ‰“å°å®éªŒæ‘˜è¦
        self.print_experiment_summary()

    def print_experiment_summary(self):
        """æ‰“å°å®éªŒç»“æœæ‘˜è¦"""
        print("\n" + "=" * 80)
        print("ğŸ“Š BERT + TIM å®éªŒç»“æœæ‘˜è¦")
        print("=" * 80)

        successful_results = {
            k: v for k, v in self.results.items() if v.get("status") == "success"
        }

        if not successful_results:
            print("âŒ æ²¡æœ‰æˆåŠŸçš„å®éªŒç»“æœ")
            return

        print(f"âœ… æˆåŠŸå®Œæˆå®éªŒ: {len(successful_results)}/{len(self.results)}")
        print()

        # æŒ‰å½±å“åŠ›ç»Ÿè®¡æ’åº
        results_by_mean_influence = sorted(
            successful_results.items(),
            key=lambda x: x[1]["statistics"]["mean_influence"],
            reverse=True,
        )

        print("ğŸ† æŒ‰å¹³å‡å½±å“åŠ›æ’å:")
        print("-" * 60)
        for i, (model_name, result) in enumerate(results_by_mean_influence, 1):
            stats = result["statistics"]
            print(f"{i}. {model_name}")
            print(f"   å¹³å‡å½±å“åŠ›: {stats['mean_influence']:.6f}")
            print(f"   æ ‡å‡†å·®: {stats['std_influence']:.6f}")
            print(f"   è®­ç»ƒæ­¥æ•°: {result['training_info']['total_steps']}")
            print()


def main():
    """ä¸»å‡½æ•° - è¿è¡ŒBERT TIMæƒ…æ„Ÿåˆ†æå®éªŒ"""

    print("ğŸš€ å¯åŠ¨BERT + TIMæƒ…æ„Ÿåˆ†æå®éªŒ")
    print("=" * 50)

    # æ˜¾ç¤ºå¯ç”¨çš„BERTæ¨¡å‹é€‰é¡¹
    model_configs = get_bert_model_configs()
    print("ğŸ“‹ å¯ç”¨çš„BERTæ¨¡å‹é€‰é¡¹:")
    for model_name, config in model_configs.items():
        print(f"  â€¢ {model_name}: {config['description']}")
    print()

    # åˆ›å»ºå®éªŒå®ä¾‹
    experiment = BertTimExperiment(
        dataset_name="imdb",  # IMDBæƒ…æ„Ÿåˆ†ææ•°æ®é›†
        train_count=500,  # è®­ç»ƒæ ·æœ¬æ•°ï¼ˆå®éªŒç”¨è¾ƒå°æ•°æ®é›†ï¼‰
        valid_count=100,  # éªŒè¯æ ·æœ¬æ•°
        test_count=100,  # æµ‹è¯•æ ·æœ¬æ•°
        random_state=42,
        output_dir="./bert_tim_results",
    )

    # é€‰æ‹©è¦æµ‹è¯•çš„æ¨¡å‹ï¼ˆæŒ‰æ¨èé¡ºåºï¼‰
    selected_models = [
        "distilbert-base-uncased",  # å¿«é€Ÿæµ‹è¯•ç”¨å°æ¨¡å‹
        "bert-base-uncased",  # æ ‡å‡†BERT
        "bert-large-uncased",  # æœ€å¤§æ ‡å‡†BERTæ¨¡å‹
    ]

    print("ğŸ¯ é€‰æ‹©æµ‹è¯•çš„æ¨¡å‹ï¼ˆæŒ‰å‚æ•°è§„æ¨¡ä»å°åˆ°å¤§ï¼‰:")
    for model in selected_models:
        print(f"  â€¢ {model}: {model_configs[model]['parameters']} å‚æ•°")
    print()

    print("âš ï¸  æ³¨æ„: è¿™æ˜¯å®éªŒä»£ç ï¼Œä¸ä¼šå®é™…è¿è¡Œè®­ç»ƒ")
    print("   å®é™…è¿è¡Œè¯·åœ¨GPUæœåŠ¡å™¨ä¸Šæ‰§è¡Œ")
    print()

    # è¿è¡Œå®éªŒå¥—ä»¶
    experiment.run_full_experiment_suite(selected_models)

    print("ğŸ‰ å®éªŒé…ç½®å®Œæˆï¼")
    print("   è¦å®é™…è¿è¡Œæ­¤å®éªŒï¼Œè¯·åœ¨æœ‰è¶³å¤ŸGPUå†…å­˜çš„æœåŠ¡å™¨ä¸Šæ‰§è¡Œæ­¤è„šæœ¬")


if __name__ == "__main__":
    main()
