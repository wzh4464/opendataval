#!/usr/bin/env python3
"""
ç»Ÿä¸€çš„BERTæƒ…æ„Ÿåˆ†æå’Œæ•°æ®ä¼°å€¼å®éªŒ (å«TIMæ–¹æ³•)
æ”¯æŒå¤šç§è®¾å¤‡ï¼ˆCPU/CUDA/MPSï¼‰ï¼Œå‘½ä»¤è¡Œå‚æ•°é…ç½®
ä½¿ç”¨é¢„è®­ç»ƒDistilBERTæ¨¡å‹è¿›è¡Œå¾®è°ƒï¼ŒåŒ…å«æ–°çš„TIMæ–¹æ³•
"""

import argparse
import json
import os
import sys
from datetime import datetime
from typing import List

import numpy as np
import torch

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from opendataval.dataval import AME, DataOob, RandomEvaluator, InfluenceFunction, TimInfluence
from opendataval.experiment import ExperimentMediator


def get_device_config(device: str = "auto") -> dict:
    """è·å–è®¾å¤‡ç›¸å…³é…ç½®"""
    if device == "auto":
        if torch.backends.mps.is_available():
            device = "mps"
        elif torch.cuda.is_available():
            device = "cuda"
        else:
            device = "cpu"
    
    # è®¾å¤‡ç‰¹å®šä¼˜åŒ–
    if device == "mps":
        # Apple Silicon MPSä¼˜åŒ–
        os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'
        os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'
        torch.set_num_threads(8)
        os.environ['CUDA_VISIBLE_DEVICES'] = ''
        print("ğŸ Apple Silicon MPSä¼˜åŒ–å·²å¯ç”¨")
        
    elif device == "cuda":
        # CUDAä¼˜åŒ–
        torch.backends.cudnn.benchmark = True
        print(f"ğŸš€ CUDAä¼˜åŒ–å·²å¯ç”¨ (è®¾å¤‡æ•°é‡: {torch.cuda.device_count()})")
        
    else:
        # CPUä¼˜åŒ–
        torch.set_num_threads(os.cpu_count() or 4)
        print("ğŸ’» CPUæ¨¡å¼å·²å¯ç”¨")
    
    return {"device": device}


def get_experiment_config(args) -> dict:
    """æ ¹æ®å‚æ•°è·å–å®éªŒé…ç½®"""
    
    # æ ¹æ®è®¾å¤‡è°ƒæ•´é»˜è®¤é…ç½®
    if args.device == "mps":
        default_batch_size = 8
        default_num_models = 15
        default_epochs = 3
    elif args.device == "cuda":
        default_batch_size = 16
        default_num_models = 25
        default_epochs = 3
    else:
        default_batch_size = 4
        default_num_models = 10
        default_epochs = 2
    
    config = {
        'dataset_name': args.dataset,
        'train_count': args.train_samples,
        'valid_count': args.valid_samples,
        'test_count': args.test_samples,
        'model_name': 'BertClassifier',
        'train_kwargs': {
            'epochs': args.epochs or default_epochs,
            'batch_size': args.batch_size or default_batch_size,
            'lr': args.learning_rate,
        },
        'evaluator_config': {
            'num_models': args.num_models or default_num_models,
        },
        'device': args.device,
        'tim_config': {
            'num_epochs': args.tim_epochs,
            'regularization': args.tim_reg,
            'window_type': args.tim_window_type,
            'start_step': args.tim_start_step,
            'end_step': args.tim_end_step,
        }
    }
    
    return config


def create_evaluators(config: dict, methods: List[str]) -> List:
    """åˆ›å»ºæ•°æ®ä¼°å€¼æ–¹æ³•è¯„ä¼°å™¨ï¼ŒåŒ…æ‹¬TIM"""
    evaluators = []
    num_models = config['evaluator_config']['num_models']
    
    for method in methods:
        if method == "random":
            evaluators.append(RandomEvaluator())
        elif method == "dataoob":
            evaluators.append(DataOob(num_models=num_models))
        elif method == "ame":
            evaluators.append(AME(num_models=num_models))
        elif method == "influence":
            # å½±å“å‡½æ•°åœ¨æŸäº›è®¾å¤‡ä¸Šå¯èƒ½ä¸ç¨³å®š
            if config['device'] != 'mps':
                evaluators.append(InfluenceFunction())
            else:
                print("âš ï¸ è·³è¿‡å½±å“å‡½æ•°æ–¹æ³•ï¼ˆMPSè®¾å¤‡ä¸ç¨³å®šï¼‰")
        elif method == "tim":
            # æ–°çš„TIMæ–¹æ³• - æ”¯æŒä»»æ„æ—¶é—´åŒºé—´
            tim_kwargs = {
                'time_window_type': config['tim_config']['window_type'],
                'num_epochs': config['tim_config']['num_epochs'],
                'regularization': config['tim_config']['regularization']
            }
            if config['tim_config']['start_step'] is not None:
                tim_kwargs['start_step'] = config['tim_config']['start_step']
            if config['tim_config']['end_step'] is not None:
                tim_kwargs['end_step'] = config['tim_config']['end_step']
                
            evaluators.append(TimInfluence(**tim_kwargs))
        else:
            print(f"âš ï¸ æœªçŸ¥çš„è¯„ä¼°æ–¹æ³•: {method}")
    
    return evaluators


def run_experiment(args) -> dict:
    """è¿è¡Œå®Œæ•´çš„BERTæƒ…æ„Ÿåˆ†æå®éªŒ"""
    
    print("=" * 60)
    print("ğŸ¤– BERTæƒ…æ„Ÿåˆ†æä¸æ•°æ®ä¼°å€¼å®éªŒ (å«TIMæ–¹æ³•)")
    print(f"ğŸ“… å®éªŒæ—¶é—´: {datetime.now()}")
    print("=" * 60)
    
    # 1. è®¾å¤‡é…ç½®
    device_config = get_device_config(args.device)
    actual_device = device_config['device']
    
    # 2. å®éªŒé…ç½®
    config = get_experiment_config(args)
    config['device'] = actual_device  # ä½¿ç”¨å®é™…æ£€æµ‹åˆ°çš„è®¾å¤‡
    
    print(f"\nğŸ“‹ å®éªŒé…ç½®:")
    print(f"   ğŸ–¥ï¸  è®¾å¤‡: {actual_device.upper()}")
    print(f"   ğŸ“š æ•°æ®é›†: {config['dataset_name']}")
    print(f"   ğŸ·ï¸  æ¨¡å‹: {config['model_name']} (å¾®è°ƒDistilBERT)")
    print(f"   ğŸ”¢ è®­ç»ƒæ ·æœ¬: {config['train_count']}")
    print(f"   ğŸ“¦ æ‰¹æ¬¡å¤§å°: {config['train_kwargs']['batch_size']}")
    print(f"   ğŸ”„ è®­ç»ƒè½®æ¬¡: {config['train_kwargs']['epochs']}")
    print(f"   ğŸ“ˆ å­¦ä¹ ç‡: {config['train_kwargs']['lr']}")
    print(f"   ğŸ¯ è¯„ä¼°æ–¹æ³•: {', '.join(args.methods)}")
    if "tim" in args.methods:
        print(f"   â° TIMå›æº¯è½®æ¬¡: {config['tim_config']['num_epochs']}")
        print(f"   ğŸ”§ TIMæ­£åˆ™åŒ–: {config['tim_config']['regularization']}")
    
    # 3. è®¾ç½®å®éªŒç¯å¢ƒ
    print(f"\nğŸ”§ è®¾ç½®å®éªŒç¯å¢ƒ...")
    try:
        exper_med = ExperimentMediator.model_factory_setup(
            dataset_name=config['dataset_name'],
            train_count=config['train_count'],
            valid_count=config['valid_count'],
            test_count=config['test_count'],
            model_name=config['model_name'],
            train_kwargs=config['train_kwargs'],
            metric_name='accuracy',
            device=actual_device,
        )
        print(f"âœ… å®éªŒç¯å¢ƒè®¾ç½®æˆåŠŸ")
        # è·å–åŸºçº¿å‡†ç¡®ç‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        try:
            baseline_accuracy = getattr(exper_med, 'model_metric', 0.0)
        except:
            baseline_accuracy = 0.0
        print(f"ğŸ“Š åŸºçº¿æ¨¡å‹å‡†ç¡®ç‡: {baseline_accuracy:.4f}")
        
    except Exception as e:
        print(f"âŒ å®éªŒç¯å¢ƒè®¾ç½®å¤±è´¥: {e}")
        return None
    
    # 4. åˆ›å»ºè¯„ä¼°å™¨
    print(f"\nğŸ§® åˆå§‹åŒ–æ•°æ®ä¼°å€¼æ–¹æ³•...")
    evaluators = create_evaluators(config, args.methods)
    
    if not evaluators:
        print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„è¯„ä¼°æ–¹æ³•")
        return None
    
    print(f"âœ… åˆ›å»ºäº† {len(evaluators)} ä¸ªè¯„ä¼°å™¨")
    for evaluator in evaluators:
        eval_name = type(evaluator).__name__
        if eval_name == "TimInfluence":
            print(f"   ğŸ†• TIM (Time-varying Influence): {evaluator.num_epochs} epochs")
        else:
            print(f"   ğŸ“Š {eval_name}")
    
    # 5. è®¡ç®—æ•°æ®ä¼°å€¼
    print(f"\nâ³ å¼€å§‹è®¡ç®—æ•°æ®ä¼°å€¼...")
    start_time = datetime.now()
    
    try:
        eval_med = exper_med.compute_data_values(evaluators)
        elapsed_time = datetime.now() - start_time
        print(f"âœ… æ•°æ®ä¼°å€¼å®Œæˆï¼Œæ€»è€—æ—¶: {elapsed_time}")
        
    except Exception as e:
        print(f"âŒ æ•°æ®ä¼°å€¼å¤±è´¥: {e}")
        return None
    
    # 6. åˆ†æç»“æœ
    print(f"\nğŸ“Š åˆ†æç»“æœ...")
    results = {
        'experiment_info': {
            'timestamp': datetime.now().isoformat(),
            'device': actual_device,
            'baseline_accuracy': float(baseline_accuracy),
            'elapsed_time': str(elapsed_time),
            'tim_enabled': "tim" in args.methods,
        },
        'config': config,
        'evaluators': {}
    }
    
    # ä¿å­˜æ•°æ®ä¼°å€¼ç»“æœ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    results_dir = "my_experiments/results"
    os.makedirs(results_dir, exist_ok=True)
    
    for evaluator in eval_med.data_evaluators:
        method_name = type(evaluator).__name__
        data_values = evaluator.data_values
        
        # ç»Ÿè®¡ä¿¡æ¯
        stats = {
            'mean': float(data_values.mean()),
            'std': float(data_values.std()),
            'min': float(data_values.min()),
            'max': float(data_values.max()),
            'median': float(np.median(data_values)),
            'shape': list(data_values.shape)
        }
        
        results['evaluators'][method_name] = stats
        
        # ä¿å­˜æ•°å€¼æ•°ç»„
        values_file = f"{results_dir}/data_values_{method_name}_{timestamp}.npy"
        np.save(values_file, data_values)
        
        print(f"\nğŸ“ˆ {method_name}:")
        print(f"   å‡å€¼: {stats['mean']:.6f}")
        print(f"   æ ‡å‡†å·®: {stats['std']:.6f}")
        print(f"   èŒƒå›´: [{stats['min']:.6f}, {stats['max']:.6f}]")
        print(f"   ä¸­ä½æ•°: {stats['median']:.6f}")
        
        if method_name == "TimInfluence":
            print(f"   ğŸ” TIMç‰¹å¾: åŸºäºæœ€å{evaluator.num_epochs}è½®è®­ç»ƒçš„å½±å“")
    
    # 7. ä¿å­˜é…ç½®å’Œç»“æœ
    config_file = f"{results_dir}/config_{timestamp}.json"
    results_file = f"{results_dir}/results_{timestamp}.json"
    
    with open(config_file, 'w', encoding='utf-8') as f:
        json.dump(config, f, indent=2, ensure_ascii=False)
    
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ ç»“æœæ–‡ä»¶:")
    print(f"   ğŸ“„ é…ç½®: {config_file}")
    print(f"   ğŸ“„ ç»“æœ: {results_file}")
    print(f"   ğŸ“„ æ•°æ®ä¼°å€¼: {results_dir}/data_values_*_{timestamp}.npy")
    
    # 8. å®éªŒæ€»ç»“
    print(f"\nğŸ¯ å®éªŒæ€»ç»“:")
    print(f"   ğŸ–¥ï¸  è®¾å¤‡: {actual_device.upper()}")
    print(f"   ğŸ¤– æ¨¡å‹: DistilBERTå¾®è°ƒ")
    print(f"   ğŸ“Š åŸºçº¿å‡†ç¡®ç‡: {baseline_accuracy:.4f}")
    print(f"   â±ï¸  æ€»è€—æ—¶: {elapsed_time}")
    print(f"   ğŸ“ˆ è¯„ä¼°æ–¹æ³•: {len(evaluators)}ç§")
    print(f"   ğŸ”¢ è®­ç»ƒæ ·æœ¬: {config['train_count']}")
    
    if "tim" in args.methods:
        print(f"   ğŸ†• TIMæ–¹æ³•å·²å¯ç”¨: æ—¶é—´çª—å£ä¸ºæœ€å{config['tim_config']['num_epochs']}è½®")
    
    if actual_device == "mps":
        print(f"\nğŸ åœ¨Apple Siliconä¸ŠæˆåŠŸè¿è¡ŒBERTå¾®è°ƒï¼")
    elif actual_device == "cuda":
        print(f"\nğŸš€ åœ¨GPUä¸ŠæˆåŠŸè¿è¡ŒBERTå¾®è°ƒï¼")
    else:
        print(f"\nğŸ’» åœ¨CPUä¸ŠæˆåŠŸè¿è¡ŒBERTå¾®è°ƒï¼")
    
    return results


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description="BERTæƒ…æ„Ÿåˆ†æä¸æ•°æ®ä¼°å€¼å®éªŒ (å«TIMæ–¹æ³•)",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    
    # åŸºç¡€é…ç½®
    parser.add_argument(
        "--device", 
        choices=["auto", "cpu", "cuda", "mps"], 
        default="auto",
        help="è®¡ç®—è®¾å¤‡ (auto=è‡ªåŠ¨æ£€æµ‹æœ€ä½³è®¾å¤‡)"
    )
    
    parser.add_argument(
        "--dataset",
        default="imdb",
        help="æ•°æ®é›†åç§°"
    )
    
    # æ•°æ®é…ç½®
    parser.add_argument(
        "--train-samples",
        type=int,
        default=200,
        help="è®­ç»ƒæ ·æœ¬æ•°é‡"
    )
    
    parser.add_argument(
        "--valid-samples", 
        type=int,
        default=100,
        help="éªŒè¯æ ·æœ¬æ•°é‡"
    )
    
    parser.add_argument(
        "--test-samples",
        type=int, 
        default=100,
        help="æµ‹è¯•æ ·æœ¬æ•°é‡"
    )
    
    # è®­ç»ƒé…ç½®
    parser.add_argument(
        "--epochs",
        type=int,
        help="è®­ç»ƒè½®æ¬¡ (é»˜è®¤æ ¹æ®è®¾å¤‡è‡ªé€‚åº”)"
    )
    
    parser.add_argument(
        "--batch-size",
        type=int,
        help="æ‰¹æ¬¡å¤§å° (é»˜è®¤æ ¹æ®è®¾å¤‡è‡ªé€‚åº”)"
    )
    
    parser.add_argument(
        "--learning-rate",
        type=float,
        default=2e-5,
        help="å­¦ä¹ ç‡ (BERTå¾®è°ƒæ¨èå€¼)"
    )
    
    # è¯„ä¼°é…ç½®  
    parser.add_argument(
        "--methods",
        nargs="+",
        choices=["random", "dataoob", "ame", "influence", "tim"],
        default=["random", "dataoob", "tim"],
        help="æ•°æ®ä¼°å€¼æ–¹æ³• (åŒ…å«æ–°çš„TIMæ–¹æ³•)"
    )
    
    parser.add_argument(
        "--num-models",
        type=int,
        help="è¯„ä¼°å™¨ä½¿ç”¨çš„æ¨¡å‹æ•°é‡ (é»˜è®¤æ ¹æ®è®¾å¤‡è‡ªé€‚åº”)"
    )
    
    # TIMç‰¹å®šé…ç½®
    parser.add_argument(
        "--tim-epochs",
        type=int,
        default=3,
        help="TIMæ–¹æ³•å›æº¯çš„epochæ•°é‡"
    )
    
    parser.add_argument(
        "--tim-reg",
        type=float,
        default=0.01,
        help="TIMæ–¹æ³•çš„L2æ­£åˆ™åŒ–å‚æ•°"
    )
    
    parser.add_argument(
        "--tim-window-type",
        choices=["last_epochs", "custom_range", "full"],
        default="last_epochs",
        help="TIMæ—¶é—´çª—å£ç±»å‹"
    )
    
    parser.add_argument(
        "--tim-start-step",
        type=int,
        help="TIMè‡ªå®šä¹‰æ—¶é—´çª—å£èµ·å§‹æ­¥éª¤"
    )
    
    parser.add_argument(
        "--tim-end-step", 
        type=int,
        help="TIMè‡ªå®šä¹‰æ—¶é—´çª—å£ç»“æŸæ­¥éª¤"
    )
    
    # è¾“å‡ºé…ç½®
    parser.add_argument(
        "--output-dir",
        default="my_experiments/results",
        help="è¾“å‡ºç›®å½•"
    )
    
    parser.add_argument(
        "--verbose",
        action="store_true", 
        help="è¯¦ç»†è¾“å‡º"
    )
    
    return parser.parse_args()


if __name__ == "__main__":
    try:
        args = parse_arguments()
        
        print(f"ğŸ” å‘½ä»¤è¡Œå‚æ•°: {vars(args)}")
        
        results = run_experiment(args)
        
        if results:
            print(f"\nâœ… å®éªŒæˆåŠŸå®Œæˆï¼")
            if "tim" in args.methods:
                print(f"ğŸ‰ TIM (Time-varying Influence Measurement) æ–¹æ³•æµ‹è¯•å®Œæˆ")
            print(f"ğŸ‰ BERTå¾®è°ƒæƒ…æ„Ÿåˆ†æå®éªŒç»“æŸ")
        else:
            print(f"\nâŒ å®éªŒå¤±è´¥")
            sys.exit(1)
            
    except KeyboardInterrupt:
        print(f"\nâš ï¸ å®éªŒè¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
        
    except Exception as e:
        print(f"\nğŸ’¥ å®éªŒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)