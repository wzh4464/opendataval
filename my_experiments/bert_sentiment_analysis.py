"""
BERTæƒ…æ„Ÿåˆ†æå®éªŒ - ä½¿ç”¨OpenDataVal TIMæ–¹æ³•

ä½¿ç”¨Time-varying Influence Measurement (TIM)è¿›è¡ŒBERTæƒ…æ„Ÿåˆ†æå¾®è°ƒçš„æ•°æ®ä»·å€¼è¯„ä¼°å®éªŒã€‚
æœ¬å®éªŒè®¾ç½® t1 = 0, t2 = Tï¼ˆå®Œæ•´è®­ç»ƒè¿‡ç¨‹ï¼‰ï¼Œä½¿ç”¨ä¸åŒå¤§å°çš„BERTæ¨¡å‹è¿›è¡Œæ¯”è¾ƒã€‚

å®éªŒé…ç½®ï¼š
- æ•°æ®é›†: IMDBç”µå½±è¯„è®ºæƒ…æ„Ÿåˆ†ææ•°æ®é›†
- æ¨¡å‹: å¤šç§BERTæ¨¡å‹å¤§å°é€‰é¡¹ï¼ˆä»DistilBERTåˆ°BERT-Largeï¼‰
- è¯„ä¼°æ–¹æ³•: TIM (Time-varying Influence Measurement)
- æ—¶é—´çª—å£: [0, T] - å®Œæ•´è®­ç»ƒè¿‡ç¨‹
"""

from pathlib import Path
from typing import Dict, List, Tuple

import numpy as np
import torch

from opendataval.dataloader import DataFetcher
from opendataval.dataval.tim import TimInfluence
from opendataval.model import BertClassifier


def get_bert_model_configs() -> Dict[str, Dict]:
    """è·å–ä¸åŒå¤§å°çš„BERTæ¨¡å‹é…ç½®

    è¿”å›ä»å°åˆ°å¤§çš„BERTæ¨¡å‹é…ç½®åˆ—è¡¨ï¼ŒåŒ…æ‹¬å‚æ•°è§„æ¨¡ä¿¡æ¯ã€‚
    æ³¨æ„ï¼šOpenDataValçš„BertClassifieråŸºäºDistilBERTæ¶æ„ï¼Œåªèƒ½ä½¿ç”¨DistilBERTé¢„è®­ç»ƒæ¨¡å‹ã€‚

    Returns:
        Dict[str, Dict]: æ¨¡å‹é…ç½®å­—å…¸ï¼Œé”®ä¸ºæ¨¡å‹åç§°ï¼Œå€¼ä¸ºé…ç½®å‚æ•°
    """
    return {
        # DistilBERTæ¨¡å‹ (OpenDataValæ”¯æŒ)
        "distilbert-base-uncased": {
            "pretrained_model_name": "distilbert-base-uncased",
            "parameters": "66M",
            "description": "DistilBERT-Base (66Må‚æ•°) - BERTçš„è½»é‡çº§ç‰ˆæœ¬ï¼Œé€Ÿåº¦å¿«",
        },
        "distilbert-base-cased": {
            "pretrained_model_name": "distilbert-base-cased", 
            "parameters": "66M",
            "description": "DistilBERT-Base-Cased (66Må‚æ•°) - åŒºåˆ†å¤§å°å†™ç‰ˆæœ¬",
        },
        # å¤šè¯­è¨€DistilBERT
        "distilbert-base-multilingual-cased": {
            "pretrained_model_name": "distilbert-base-multilingual-cased",
            "parameters": "134M", 
            "description": "DistilBERTå¤šè¯­è¨€ (134Må‚æ•°) - æ”¯æŒå¤šç§è¯­è¨€",
        },
        # æ³¨æ„ï¼šæ ‡å‡†BERTæ¨¡å‹ä¸DistilBERTæ¶æ„ä¸å…¼å®¹ï¼Œå·²ç§»é™¤
        # å¦‚éœ€ä½¿ç”¨æ›´å¤§æ¨¡å‹ï¼Œéœ€è¦ä¿®æ”¹BertClassifierç±»çš„å®ç°
    }


class BertTimExperiment:
    """BERT + TIM æƒ…æ„Ÿåˆ†æå®éªŒç±»"""

    def __init__(
        self,
        dataset_name: str = "imdb",
        train_count: int = 1000,
        valid_count: int = 200,
        test_count: int = 200,
        random_state: int = 42,
        output_dir: str = "./results",
    ):
        """
        åˆå§‹åŒ–å®éªŒé…ç½®

        Parameters:
        -----------
        dataset_name : str
            æ•°æ®é›†åç§°ï¼Œé»˜è®¤"imdb"ç”¨äºæƒ…æ„Ÿåˆ†æ
        train_count : int
            è®­ç»ƒæ ·æœ¬æ•°é‡
        valid_count : int
            éªŒè¯æ ·æœ¬æ•°é‡
        test_count : int
            æµ‹è¯•æ ·æœ¬æ•°é‡
        random_state : int
            éšæœºç§å­
        output_dir : str
            ç»“æœè¾“å‡ºç›®å½•
        """
        self.dataset_name = dataset_name
        self.train_count = train_count
        self.valid_count = valid_count
        self.test_count = test_count
        self.random_state = random_state
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # è®¾ç½®éšæœºç§å­
        torch.manual_seed(random_state)
        np.random.seed(random_state)

        # å®éªŒç»“æœå­˜å‚¨
        self.results = {}

    def prepare_data(
        self,
    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:
        """å‡†å¤‡IMDBæƒ…æ„Ÿåˆ†ææ•°æ®"""
        print(f"ğŸ”„ åŠ è½½æ•°æ®é›†: {self.dataset_name}")
        print(
            f"ğŸ“Š æ•°æ®è§„æ¨¡: è®­ç»ƒ={self.train_count}, éªŒè¯={self.valid_count}, æµ‹è¯•={self.test_count}"
        )

        # ä½¿ç”¨DataFetcher.setupåŠ è½½IMDBæ•°æ®é›†ï¼Œå¹¶æŒ‡å®šæ•°æ®åˆ†å‰²
        fetcher = DataFetcher.setup(
            dataset_name=self.dataset_name,
            train_count=self.train_count,
            valid_count=self.valid_count,
            test_count=self.test_count,
            random_state=self.random_state,
        )

        # è·å–åŸå§‹æ–‡æœ¬æ•°æ®ï¼ˆä¸ä½¿ç”¨embeddingï¼‰
        x_train, y_train, x_valid, y_valid, x_test, y_test = fetcher.datapoints
        
        # è½¬æ¢æ•°æ®ç±»å‹ä»¥ç¡®ä¿å…¼å®¹æ€§
        if hasattr(x_train, 'dataset'):
            # å¦‚æœæ˜¯Subsetå¯¹è±¡ï¼Œæå–å®é™…æ•°æ®
            x_train_data = [x_train.dataset[i] for i in x_train.indices]
            x_valid_data = [x_valid.dataset[i] for i in x_valid.indices] 
            x_test_data = [x_test.dataset[i] for i in x_test.indices]
        else:
            x_train_data, x_valid_data, x_test_data = x_train, x_valid, x_test
            
        # ç¡®ä¿æ ‡ç­¾æ˜¯torch tensoræ ¼å¼ï¼Œå¹¶è½¬æ¢one-hotä¸ºç´¢å¼•
        if not isinstance(y_train, torch.Tensor):
            y_train = torch.tensor(y_train, dtype=torch.long)
        if not isinstance(y_valid, torch.Tensor):
            y_valid = torch.tensor(y_valid, dtype=torch.long)
        if not isinstance(y_test, torch.Tensor):
            y_test = torch.tensor(y_test, dtype=torch.long)
            
        # å¦‚æœæ˜¯one-hotç¼–ç ï¼Œè½¬æ¢ä¸ºç´¢å¼•æ ¼å¼
        if len(y_train.shape) > 1 and y_train.shape[1] > 1:
            y_train = torch.argmax(y_train, dim=1)
            print(f"   è½¬æ¢one-hotæ ‡ç­¾ä¸ºç´¢å¼•: {y_train[:5]}")
        if len(y_valid.shape) > 1 and y_valid.shape[1] > 1:
            y_valid = torch.argmax(y_valid, dim=1)
        if len(y_test.shape) > 1 and y_test.shape[1] > 1:
            y_test = torch.argmax(y_test, dim=1)

        print("âœ… æ•°æ®åŠ è½½å®Œæˆ")
        print(f"   è®­ç»ƒé›†æ ·æœ¬æ•°: {len(x_train_data)}")
        print(f"   éªŒè¯é›†æ ·æœ¬æ•°: {len(x_valid_data)}")
        print(f"   æµ‹è¯•é›†æ ·æœ¬æ•°: {len(x_test_data)}")
        print(f"   ç±»åˆ«æ•°: {len(np.unique(y_train))}")
        
        # è¿”å›å¤„ç†åçš„æ•°æ®
        return x_train_data, y_train, x_valid_data, y_valid, x_test_data, y_test

        return x_train, y_train, x_valid, y_valid, x_test, y_test

    def create_bert_model(self, model_config: Dict) -> BertClassifier:
        """åˆ›å»ºBERTåˆ†ç±»å™¨æ¨¡å‹"""
        model = BertClassifier(
            pretrained_model_name=model_config["pretrained_model_name"],
            num_classes=2,  # äºŒåˆ†ç±»æƒ…æ„Ÿåˆ†æ
            dropout_rate=0.2,
            num_train_layers=2,  # å¾®è°ƒæœ€å2å±‚
        )

        # æ™ºèƒ½è®¾å¤‡é€‰æ‹©ï¼Œä¼˜å…ˆGPU
        if torch.cuda.is_available():
            device = torch.device("cuda")
            print("ğŸš€ ä½¿ç”¨CUDA GPUåŠ é€Ÿ")
        elif torch.backends.mps.is_available():
            device = torch.device("mps")
            print("ğŸ ä½¿ç”¨Apple Silicon MPSåŠ é€Ÿ")
            # MPSä¼˜åŒ–è®¾ç½®
            import os
            os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'
        else:
            device = torch.device("cpu")
            print("ğŸ’» ä½¿ç”¨CPU (æœªæ£€æµ‹åˆ°GPU)")
            
        model = model.to(device)

        print(f"ğŸ¤– åˆ›å»ºæ¨¡å‹: {model_config['description']}")
        print(f"ğŸ“ è®¾å¤‡: {device}")

        return model

    def setup_tim_evaluator(
        self, t1: int = 0, t2: int = None, num_epochs: int = 5, batch_size: int = 16
    ) -> TimInfluence:
        """
        è®¾ç½®TIMè¯„ä¼°å™¨

        Parameters:
        -----------
        t1 : int
            æ—¶é—´çª—å£å¼€å§‹æ­¥éª¤ï¼Œé»˜è®¤0ï¼ˆä»å¼€å§‹ï¼‰
        t2 : int
            æ—¶é—´çª—å£ç»“æŸæ­¥éª¤ï¼ŒNoneè¡¨ç¤ºåˆ°ç»“æŸï¼ˆTï¼‰
        num_epochs : int
            è®­ç»ƒè½®æ•°
        batch_size : int
            æ‰¹å¤„ç†å¤§å°
        """
        print("âš™ï¸  è®¾ç½®TIMè¯„ä¼°å™¨")
        print(f"   æ—¶é—´çª—å£: t1={t1}, t2={'T(end)' if t2 is None else t2}")
        print(f"   è®­ç»ƒé…ç½®: epochs={num_epochs}, batch_size={batch_size}")

        tim_evaluator = TimInfluence(
            start_step=t1,
            end_step=t2,
            time_window_type="full" if t1 == 0 and t2 is None else "custom_range",
            num_epochs=num_epochs,
            batch_size=batch_size,
            regularization=0.01,
            finite_diff_eps=1e-5,
            random_state=self.random_state,
        )

        return tim_evaluator

    def run_single_experiment(
        self, model_name: str, model_config: Dict, data: Tuple, tim_config: Dict = None
    ) -> Dict:
        """è¿è¡Œå•ä¸ªBERT+TIMå®éªŒ"""
        x_train, y_train, x_valid, y_valid, x_test, y_test = data

        print("\n" + "=" * 60)
        print(f"ğŸ”¬ å¼€å§‹å®éªŒ: {model_name}")
        print(f"ğŸ“ {model_config['description']}")
        print("=" * 60)

        # é»˜è®¤TIMé…ç½®
        if tim_config is None:
            tim_config = {
                "t1": 0,
                "t2": None,  # åˆ°ç»“æŸ
                "num_epochs": 3,
                "batch_size": 8,  # BERTéœ€è¦è¾ƒå°çš„batch size
            }

        try:
            # 1. åˆ›å»ºæ¨¡å‹
            model = self.create_bert_model(model_config)

            # 2. è®¾ç½®TIMè¯„ä¼°å™¨
            tim_evaluator = self.setup_tim_evaluator(**tim_config)

            # 3. è¾“å…¥æ•°æ®åˆ°TIM - éœ€è¦è½¬æ¢ä¸ºtensoræ ¼å¼
            # TIMå†…éƒ¨éœ€è¦tensoræ•°æ®ï¼Œä½†æˆ‘ä»¬æœ‰æ–‡æœ¬æ•°æ®ï¼Œéœ€è¦å…ˆtokenize
            print("   ğŸ”„ å¯¹æ–‡æœ¬æ•°æ®è¿›è¡Œtokenization...")
            
            # ä½¿ç”¨æ¨¡å‹çš„tokenizerå¤„ç†æ–‡æœ¬æ•°æ®
            train_dataset = model.tokenize(x_train)
            valid_dataset = model.tokenize(x_valid)
            
            # è·å–tokenizedçš„tensoræ•°æ®
            train_input_ids = train_dataset.tensors[0]
            train_attention_mask = train_dataset.tensors[1]  
            valid_input_ids = valid_dataset.tensors[0]
            valid_attention_mask = valid_dataset.tensors[1]
            
            # ç¡®ä¿æ•°æ®åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
            device = model.bert.device
            train_input_ids = train_input_ids.to(device)
            train_attention_mask = train_attention_mask.to(device)
            valid_input_ids = valid_input_ids.to(device)
            valid_attention_mask = valid_attention_mask.to(device)
            y_train = y_train.to(device)
            y_valid = y_valid.to(device)
            
            # ä¸ºTIMåˆ›å»ºç®€åŒ–çš„tensorè¾“å…¥ï¼ˆè½¬æ¢ä¸ºfloatä»¥æ”¯æŒæ¢¯åº¦è®¡ç®—ï¼‰
            tim_evaluator.input_data(
                x_train=train_input_ids.float(),
                y_train=y_train,
                x_valid=valid_input_ids.float(),
                y_valid=y_valid
            )

            # 4. åˆ›å»ºTIMå…¼å®¹çš„BERTåŒ…è£…å™¨
            class BertTimWrapper(torch.nn.Module):
                """åŒ…è£…BERTæ¨¡å‹ä»¥å…¼å®¹TIMçš„tensorè¾“å…¥æ ¼å¼"""
                def __init__(self, bert_model, attention_mask):
                    super().__init__()
                    self.bert_model = bert_model
                    self.attention_mask = attention_mask.detach()  # é¿å…æ¢¯åº¦é—®é¢˜
                    
                def forward(self, input_ids):
                    # TIMä¼ é€’çš„æ˜¯float tensorï¼Œæˆ‘ä»¬éœ€è¦è½¬æ¢ä¸ºtoken IDs
                    batch_size = input_ids.shape[0]
                    device = input_ids.device
                    
                    # ä½¿ç”¨å¯¹åº”çš„attention maskç‰‡æ®µ  
                    mask = self.attention_mask[:batch_size].to(device)
                    
                    # å°†float tensorè½¬ä¸ºlong token IDs
                    input_ids_long = input_ids.long()
                    
                    # è°ƒç”¨BERTå¹¶è·å–logitsï¼ˆä¸è¦softmaxï¼‰
                    outputs = self.bert_model(input_ids_long, attention_mask=mask)
                    
                    # ç§»é™¤æœ€åçš„Softmaxå±‚ï¼Œç›´æ¥è¿”å›logitsä»¥ä¾¿æ¢¯åº¦ä¼ æ’­
                    # BERT classifierçš„æœ€åä¸€å±‚æ˜¯softmaxï¼Œæˆ‘ä»¬éœ€è¦raw logits
                    if hasattr(self.bert_model, 'classifier'):
                        # è·å–åˆ†ç±»å™¨ä¹‹å‰çš„hidden states
                        hidden_states = self.bert_model.bert(input_ids_long, attention_mask=mask)[0]
                        pooled_output = hidden_states[:, 0]  # [CLS] token
                        
                        # åªé€šè¿‡linearå±‚ï¼Œä¸è¦softmax
                        pre_linear = self.bert_model.classifier.pre_linear(pooled_output)
                        activated = self.bert_model.classifier.acti(pre_linear)
                        dropped = self.bert_model.classifier.dropout(activated)
                        logits = self.bert_model.classifier.linear(dropped)
                        
                        return logits  # è¿”å›raw logitsè€Œä¸æ˜¯softmaxè¾“å‡º
                    else:
                        return outputs
                    
                def predict(self, input_ids):
                    """TIMè°ƒç”¨çš„é¢„æµ‹æ¥å£"""
                    with torch.enable_grad():
                        return self.forward(input_ids)
                    
                def parameters(self):
                    return self.bert_model.parameters()
                    
                def named_parameters(self):
                    return self.bert_model.named_parameters()
                    
                def zero_grad(self):
                    return self.bert_model.zero_grad()
                    
                def train(self):
                    self.bert_model.train()
                    return self
                    
                def eval(self):
                    self.bert_model.eval() 
                    return self
            
            # åˆ›å»ºåŒ…è£…å™¨
            bert_wrapper = BertTimWrapper(model, train_attention_mask)
            tim_evaluator.pred_model = bert_wrapper

            # 5. è®­ç»ƒå¹¶è®°å½•çŠ¶æ€
            print("\nğŸš€ å¼€å§‹TIMè®­ç»ƒ...")
            tim_evaluator.train_data_values(
                epochs=tim_config["num_epochs"],
                batch_size=tim_config["batch_size"],
                lr=2e-5,  # BERTæ¨èå­¦ä¹ ç‡
            )

            # 6. è®¡ç®—å½±å“åŠ›æ•°æ®å€¼
            print("\nğŸ“Š è®¡ç®—æ•°æ®å½±å“åŠ›...")
            data_values = tim_evaluator.evaluate_data_values()

            # 7. åˆ†æç»“æœ
            results = self.analyze_results(
                model_name=model_name,
                data_values=data_values,
                tim_evaluator=tim_evaluator,
                y_train=y_train,
            )

            print(f"âœ… å®éªŒå®Œæˆ: {model_name}")
            return results

        except Exception as e:
            print(f"âŒ å®éªŒå¤±è´¥: {model_name}")
            print(f"   é”™è¯¯: {e!s}")
            return {"model_name": model_name, "status": "failed", "error": str(e)}

    def analyze_results(
        self,
        model_name: str,
        data_values: np.ndarray,
        tim_evaluator: TimInfluence,
        y_train: torch.Tensor,
    ) -> Dict:
        """åˆ†æTIMå®éªŒç»“æœ"""

        # åŸºç¡€ç»Ÿè®¡
        mean_influence = float(np.mean(data_values))
        std_influence = float(np.std(data_values))
        min_influence = float(np.min(data_values))
        max_influence = float(np.max(data_values))

        # æŒ‰ç±»åˆ«åˆ†æå½±å“åŠ› - ç¡®ä¿tensoråœ¨CPUä¸Š
        if isinstance(y_train, torch.Tensor):
            y_train_np = y_train.cpu().numpy()
        else:
            y_train_np = y_train

        positive_indices = np.where(y_train_np == 1)[0]
        negative_indices = np.where(y_train_np == 0)[0]

        positive_influence = data_values[positive_indices]
        negative_influence = data_values[negative_indices]

        # æ‰¾å‡ºæœ€æœ‰å½±å“åŠ›çš„æ ·æœ¬
        top_k = 10
        most_influential_indices = np.argsort(data_values)[-top_k:][::-1]
        least_influential_indices = np.argsort(data_values)[:top_k]

        results = {
            "model_name": model_name,
            "status": "success",
            "data_values": data_values.tolist(),
            "statistics": {
                "mean_influence": mean_influence,
                "std_influence": std_influence,
                "min_influence": min_influence,
                "max_influence": max_influence,
                "total_samples": len(data_values),
            },
            "class_analysis": {
                "positive_samples": {
                    "count": len(positive_influence),
                    "mean_influence": float(np.mean(positive_influence)),
                    "std_influence": float(np.std(positive_influence)),
                },
                "negative_samples": {
                    "count": len(negative_influence),
                    "mean_influence": float(np.mean(negative_influence)),
                    "std_influence": float(np.std(negative_influence)),
                },
            },
            "top_influential": {
                "indices": most_influential_indices.tolist(),
                "values": data_values[most_influential_indices].tolist(),
            },
            "least_influential": {
                "indices": least_influential_indices.tolist(),
                "values": data_values[least_influential_indices].tolist(),
            },
            "training_info": {
                "total_steps": tim_evaluator.total_steps,
                "steps_per_epoch": tim_evaluator.steps_per_epoch,
                "cached_intervals": len(tim_evaluator._influence_cache),
            },
        }

        # æ‰“å°å…³é”®ç»“æœ
        print("\nğŸ“ˆ å®éªŒç»“æœæ‘˜è¦:")
        print(f"   å¹³å‡å½±å“åŠ›: {mean_influence:.6f}")
        print(f"   å½±å“åŠ›æ ‡å‡†å·®: {std_influence:.6f}")
        print(f"   å½±å“åŠ›èŒƒå›´: [{min_influence:.6f}, {max_influence:.6f}]")
        print(
            f"   æ­£é¢æ ·æœ¬å¹³å‡å½±å“åŠ›: {results['class_analysis']['positive_samples']['mean_influence']:.6f}"
        )
        print(
            f"   è´Ÿé¢æ ·æœ¬å¹³å‡å½±å“åŠ›: {results['class_analysis']['negative_samples']['mean_influence']:.6f}"
        )
        print(f"   è®­ç»ƒæ€»æ­¥æ•°: {tim_evaluator.total_steps}")

        return results

    def save_results(self, filename: str = None):
        """ä¿å­˜å®éªŒç»“æœåˆ°JSONæ–‡ä»¶"""
        import json

        if filename is None:
            filename = "bert_tim_experiment_results.json"

        filepath = self.output_dir / filename

        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)

        print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {filepath}")

    def run_full_experiment_suite(self, selected_models: List[str] = None):
        """è¿è¡Œå®Œæ•´çš„BERTæ¨¡å‹å¯¹æ¯”å®éªŒ"""

        print("ğŸ”¬ BERT + TIM æƒ…æ„Ÿåˆ†æå®éªŒå¥—ä»¶")
        print("=" * 80)

        # è·å–æ¨¡å‹é…ç½®
        model_configs = get_bert_model_configs()

        if selected_models is None:
            # é»˜è®¤é€‰æ‹©æ”¯æŒçš„DistilBERTæ¨¡å‹
            selected_models = [
                "distilbert-base-uncased",  # åŸºç¡€: 66Må‚æ•°
                "distilbert-base-cased",    # åŒºåˆ†å¤§å°å†™: 66Må‚æ•°  
                "distilbert-base-multilingual-cased",  # å¤šè¯­è¨€: 134Må‚æ•° (æœ€å¤§)
            ]

        print(f"ğŸ“‹ é€‰æ‹©çš„æ¨¡å‹: {selected_models}")

        # å‡†å¤‡æ•°æ®ï¼ˆæ‰€æœ‰å®éªŒä½¿ç”¨ç›¸åŒæ•°æ®ï¼‰
        data = self.prepare_data()

        # TIMé…ç½® - è®¾ç½® t1=0, t2=Tï¼ˆå®Œæ•´è®­ç»ƒè¿‡ç¨‹ï¼‰
        tim_config = {
            "t1": 0,  # ä»è®­ç»ƒå¼€å§‹
            "t2": None,  # åˆ°è®­ç»ƒç»“æŸï¼ˆTï¼‰
            "num_epochs": 2,  # å‡å°‘epochæ•°ä»¥é€‚åº”å®éªŒ
            "batch_size": 8,  # è¾ƒå°çš„batch sizeé€‚åˆBERT
        }

        print(
            f"âš™ï¸  TIMé…ç½®: t1={tim_config['t1']}, t2=T, epochs={tim_config['num_epochs']}"
        )

        # è¿è¡Œæ¯ä¸ªæ¨¡å‹çš„å®éªŒ
        for model_name in selected_models:
            if model_name not in model_configs:
                print(f"âš ï¸  è·³è¿‡æœªçŸ¥æ¨¡å‹: {model_name}")
                continue

            model_config = model_configs[model_name]

            # è¿è¡Œå®éªŒ
            result = self.run_single_experiment(
                model_name=model_name,
                model_config=model_config,
                data=data,
                tim_config=tim_config,
            )

            self.results[model_name] = result

        # ä¿å­˜ç»“æœ
        self.save_results()

        # æ‰“å°å®éªŒæ‘˜è¦
        self.print_experiment_summary()

    def print_experiment_summary(self):
        """æ‰“å°å®éªŒç»“æœæ‘˜è¦"""
        print("\n" + "=" * 80)
        print("ğŸ“Š BERT + TIM å®éªŒç»“æœæ‘˜è¦")
        print("=" * 80)

        successful_results = {
            k: v for k, v in self.results.items() if v.get("status") == "success"
        }

        if not successful_results:
            print("âŒ æ²¡æœ‰æˆåŠŸçš„å®éªŒç»“æœ")
            return

        print(f"âœ… æˆåŠŸå®Œæˆå®éªŒ: {len(successful_results)}/{len(self.results)}")
        print()

        # æŒ‰å½±å“åŠ›ç»Ÿè®¡æ’åº
        results_by_mean_influence = sorted(
            successful_results.items(),
            key=lambda x: x[1]["statistics"]["mean_influence"],
            reverse=True,
        )

        print("ğŸ† æŒ‰å¹³å‡å½±å“åŠ›æ’å:")
        print("-" * 60)
        for i, (model_name, result) in enumerate(results_by_mean_influence, 1):
            stats = result["statistics"]
            print(f"{i}. {model_name}")
            print(f"   å¹³å‡å½±å“åŠ›: {stats['mean_influence']:.6f}")
            print(f"   æ ‡å‡†å·®: {stats['std_influence']:.6f}")
            print(f"   è®­ç»ƒæ­¥æ•°: {result['training_info']['total_steps']}")
            print()


def main():
    """ä¸»å‡½æ•° - è¿è¡ŒBERT TIMæƒ…æ„Ÿåˆ†æå®éªŒ"""

    print("ğŸš€ å¯åŠ¨BERT + TIMæƒ…æ„Ÿåˆ†æå®éªŒ")
    print("=" * 50)

    # æ˜¾ç¤ºå¯ç”¨çš„BERTæ¨¡å‹é€‰é¡¹
    model_configs = get_bert_model_configs()
    print("ğŸ“‹ å¯ç”¨çš„BERTæ¨¡å‹é€‰é¡¹:")
    for model_name, config in model_configs.items():
        print(f"  â€¢ {model_name}: {config['description']}")
    print()

    # åˆ›å»ºå®éªŒå®ä¾‹
    experiment = BertTimExperiment(
        dataset_name="imdb",  # IMDBæƒ…æ„Ÿåˆ†ææ•°æ®é›†
        train_count=500,  # è®­ç»ƒæ ·æœ¬æ•°ï¼ˆå®éªŒç”¨è¾ƒå°æ•°æ®é›†ï¼‰
        valid_count=100,  # éªŒè¯æ ·æœ¬æ•°
        test_count=100,  # æµ‹è¯•æ ·æœ¬æ•°
        random_state=42,
        output_dir="./bert_tim_results",
    )

    # é€‰æ‹©è¦æµ‹è¯•çš„æ¨¡å‹ï¼ˆæŒ‰æ¨èé¡ºåºï¼Œä»…æ”¯æŒDistilBERTï¼‰
    selected_models = [
        "distilbert-base-uncased",  # åŸºç¡€æ¨¡å‹
        "distilbert-base-cased",    # åŒºåˆ†å¤§å°å†™
        "distilbert-base-multilingual-cased",  # æœ€å¤§çš„å¤šè¯­è¨€æ¨¡å‹
    ]

    print("ğŸ¯ é€‰æ‹©æµ‹è¯•çš„æ¨¡å‹ï¼ˆDistilBERTç³»åˆ—ï¼ŒæŒ‰å‚æ•°è§„æ¨¡ï¼‰:")
    for model in selected_models:
        print(f"  â€¢ {model}: {model_configs[model]['parameters']} å‚æ•°")
    print()
    
    print("â„¹ï¸  è¯´æ˜: OpenDataValçš„BertClassifieråŸºäºDistilBERTæ¶æ„")
    print("   åªæ”¯æŒDistilBERTç³»åˆ—é¢„è®­ç»ƒæ¨¡å‹ï¼Œä¸æ”¯æŒæ ‡å‡†BERT/RoBERTa")
    print("   å®éªŒåœ¨GPUæœåŠ¡å™¨ä¸Šè¿è¡Œ")
    print()

    # è¿è¡Œå®éªŒå¥—ä»¶
    experiment.run_full_experiment_suite(selected_models)

    print("ğŸ‰ DistilBERT + TIM å®éªŒé…ç½®å®Œæˆï¼")
    print("   å·²ä¿®å¤æ¨¡å‹å…¼å®¹æ€§å’Œæ•°æ®å¤„ç†é—®é¢˜")


if __name__ == "__main__":
    main()
