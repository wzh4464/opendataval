#!/usr/bin/env python3
"""
å™ªå£°æ•°æ®å‰ªæå®éªŒä¸»è„šæœ¬

å®Œæ•´çš„BERT + TIMå™ªå£°æ•°æ®å½±å“åŠ›åˆ†æå’Œå‰ªæå®éªŒæµç¨‹ï¼š
1. åŠ è½½å¹²å‡€æ•°æ®
2. æ³¨å…¥30%æ ‡ç­¾å™ªå£° 
3. è®­ç»ƒBERTæ¨¡å‹ï¼Œè®°å½•æŸå¤±æ›²çº¿å’Œ[0,T]å½±å“åŠ›åˆ†æ•°
4. ç§»é™¤å½±å“åŠ›æœ€ä½çš„30%æ ·æœ¬
5. ç”¨ç›¸åŒåˆå§‹åŒ–é‡æ–°è®­ç»ƒ
6. å¯¹æ¯”åˆ†ææ€§èƒ½å’Œæ”¶æ•›æ€§
"""

import sys
import traceback
from pathlib import Path
from typing import Dict, Any, Optional
import json
import torch
import numpy as np
import time

# å¯¼å…¥æˆ‘ä»¬çš„æ¨¡å—
from my_experiments.noise_data_module import create_noise_processor
from my_experiments.bert_training_module import create_bert_trainer
from my_experiments.tim_influence_module import create_tim_calculator
from my_experiments.visualization_module import create_visualizer


class NoisePruningExperiment:
    """å™ªå£°æ•°æ®å‰ªæå®éªŒç±»"""
    
    def __init__(
        self,
        # æ•°æ®é…ç½®
        dataset_name: str = "imdb",
        train_count: int = 1000,
        valid_count: int = 200,
        test_count: int = 200,
        noise_rate: float = 0.3,
        
        # æ¨¡å‹é…ç½®
        model_name: str = "distilbert-base-uncased",
        num_classes: int = 2,
        dropout_rate: float = 0.2,
        num_train_layers: int = 2,
        
        # è®­ç»ƒé…ç½®
        epochs: int = 5,
        batch_size: int = 16,
        learning_rate: float = 2e-5,
        
        # TIMé…ç½®
        tim_epochs: int = 3,
        tim_batch_size: int = 8,
        t1: int = 0,
        t2: Optional[int] = None,
        regularization: float = 0.01,
        finite_diff_eps: float = 1e-5,
        
        # å‰ªæé…ç½®
        prune_ratio: float = 0.3,
        
        # å®éªŒé…ç½®
        random_state: int = 42,
        device: str = "auto",
        output_dir: str = "./noise_pruning_results",
        save_plots: bool = True
    ):
        """
        åˆå§‹åŒ–å™ªå£°å‰ªæå®éªŒ
        
        Parameters:
        -----------
        dataset_name : str
            æ•°æ®é›†åç§°ï¼Œé»˜è®¤"imdb"
        train_count : int
            è®­ç»ƒæ ·æœ¬æ•°ï¼Œé»˜è®¤1000
        valid_count : int
            éªŒè¯æ ·æœ¬æ•°ï¼Œé»˜è®¤200
        test_count : int
            æµ‹è¯•æ ·æœ¬æ•°ï¼Œé»˜è®¤200
        noise_rate : float
            æ ‡ç­¾å™ªå£°æ¯”ä¾‹ï¼Œé»˜è®¤0.3 (30%)
        model_name : str
            BERTæ¨¡å‹åç§°ï¼Œé»˜è®¤"distilbert-base-uncased"
        num_classes : int
            åˆ†ç±»ç±»åˆ«æ•°ï¼Œé»˜è®¤2
        dropout_rate : float
            Dropoutç‡ï¼Œé»˜è®¤0.2
        num_train_layers : int
            å¾®è°ƒå±‚æ•°ï¼Œé»˜è®¤2
        epochs : int
            è®­ç»ƒè½®æ•°ï¼Œé»˜è®¤5
        batch_size : int
            æ‰¹æ¬¡å¤§å°ï¼Œé»˜è®¤16
        learning_rate : float
            å­¦ä¹ ç‡ï¼Œé»˜è®¤2e-5
        tim_epochs : int
            TIMè®­ç»ƒè½®æ•°ï¼Œé»˜è®¤3
        tim_batch_size : int
            TIMæ‰¹æ¬¡å¤§å°ï¼Œé»˜è®¤8
        t1 : int
            TIMæ—¶é—´çª—å£å¼€å§‹ï¼Œé»˜è®¤0
        t2 : Optional[int]
            TIMæ—¶é—´çª—å£ç»“æŸï¼Œé»˜è®¤None (åˆ°ç»“æŸ)
        regularization : float
            L2æ­£åˆ™åŒ–ï¼Œé»˜è®¤0.01
        finite_diff_eps : float
            æœ‰é™å·®åˆ†å‚æ•°ï¼Œé»˜è®¤1e-5
        prune_ratio : float
            å‰ªææ¯”ä¾‹ï¼Œé»˜è®¤0.3 (30%)
        random_state : int
            éšæœºç§å­ï¼Œé»˜è®¤42
        device : str
            è®¡ç®—è®¾å¤‡ï¼Œé»˜è®¤"auto"
        output_dir : str
            ç»“æœä¿å­˜ç›®å½•ï¼Œé»˜è®¤"./noise_pruning_results"
        save_plots : bool
            æ˜¯å¦ä¿å­˜å›¾è¡¨ï¼Œé»˜è®¤True
        """
        
        # ä¿å­˜æ‰€æœ‰é…ç½®
        self.config = {
            'dataset_name': dataset_name,
            'train_count': train_count,
            'valid_count': valid_count,
            'test_count': test_count,
            'noise_rate': noise_rate,
            'model_name': model_name,
            'num_classes': num_classes,
            'dropout_rate': dropout_rate,
            'num_train_layers': num_train_layers,
            'epochs': epochs,
            'batch_size': batch_size,
            'learning_rate': learning_rate,
            'tim_epochs': tim_epochs,
            'tim_batch_size': tim_batch_size,
            't1': t1,
            't2': t2,
            'regularization': regularization,
            'finite_diff_eps': finite_diff_eps,
            'prune_ratio': prune_ratio,
            'random_state': random_state,
            'device': device,
            'output_dir': output_dir,
            'save_plots': save_plots
        }
        
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.data_processor = None
        self.bert_trainer = None
        self.tim_calculator = None
        self.visualizer = None
        
        # å®éªŒç»“æœå­˜å‚¨
        self.results = {
            'config': self.config,
            'start_time': None,
            'end_time': None,
            'status': 'initialized',
            'data_stats': {},
            'original_training': {},
            'influence_analysis': {},
            'pruning_analysis': {},
            'pruned_training': {},
            'comparative_analysis': {},
            'error_log': []
        }
        
    def setup_components(self):
        """è®¾ç½®å®éªŒç»„ä»¶"""
        print("âš™ï¸  è®¾ç½®å®éªŒç»„ä»¶...")
        
        try:
            # 1. æ•°æ®å¤„ç†å™¨
            self.data_processor = create_noise_processor(
                dataset_name=self.config['dataset_name'],
                train_count=self.config['train_count'],
                valid_count=self.config['valid_count'],
                test_count=self.config['test_count'],
                noise_rate=self.config['noise_rate'],
                random_state=self.config['random_state']
            )
            
            # 2. BERTè®­ç»ƒå™¨
            self.bert_trainer = create_bert_trainer(
                model_name=self.config['model_name'],
                num_classes=self.config['num_classes'],
                dropout_rate=self.config['dropout_rate'],
                num_train_layers=self.config['num_train_layers'],
                device=self.config['device'],
                random_state=self.config['random_state']
            )
            
            # 3. TIMè®¡ç®—å™¨
            self.tim_calculator = create_tim_calculator(
                t1=self.config['t1'],
                t2=self.config['t2'],
                num_epochs=self.config['tim_epochs'],
                batch_size=self.config['tim_batch_size'],
                regularization=self.config['regularization'],
                finite_diff_eps=self.config['finite_diff_eps'],
                random_state=self.config['random_state']
            )
            
            # 4. å¯è§†åŒ–å™¨
            if self.config['save_plots']:
                self.visualizer = create_visualizer(
                    save_dir=str(self.output_dir / "plots")
                )
            
            print("âœ… å®éªŒç»„ä»¶è®¾ç½®å®Œæˆ")
            
        except Exception as e:
            error_msg = f"ç»„ä»¶è®¾ç½®å¤±è´¥: {e}"
            print(f"âŒ {error_msg}")
            self.results['error_log'].append(error_msg)
            raise
            
    def prepare_data(self) -> Dict:
        """å‡†å¤‡å®éªŒæ•°æ®"""
        print("ğŸ”„ å‡†å¤‡å®éªŒæ•°æ®...")
        
        try:
            # 1. åŠ è½½å¹²å‡€æ•°æ®
            clean_data = self.data_processor.load_clean_data()
            
            # 2. æ³¨å…¥æ ‡ç­¾å™ªå£°
            noisy_data, noise_indices = self.data_processor.inject_label_noise()
            
            # 3. è·å–å™ªå£°ç»Ÿè®¡
            noise_stats = self.data_processor.get_noise_statistics()
            
            # ä¿å­˜æ•°æ®ç»Ÿè®¡
            self.results['data_stats'] = {
                'clean_data_info': {
                    'train_samples': len(clean_data['y_train']),
                    'valid_samples': len(clean_data['y_valid']),
                    'test_samples': len(clean_data['y_test'])
                },
                'noise_info': noise_stats
            }
            
            print("âœ… æ•°æ®å‡†å¤‡å®Œæˆ")
            print(f"   æ€»è®­ç»ƒæ ·æœ¬: {len(noisy_data['y_train'])}")
            print(f"   å™ªå£°æ ·æœ¬: {len(noise_indices)} ({len(noise_indices)/len(noisy_data['y_train'])*100:.1f}%)") 
            
            return noisy_data, noise_indices
            
        except Exception as e:
            error_msg = f"æ•°æ®å‡†å¤‡å¤±è´¥: {e}"
            print(f"âŒ {error_msg}")
            self.results['error_log'].append(error_msg)
            raise
            
    def train_original_model(self, data: Dict) -> Dict:
        """è®­ç»ƒåŸå§‹ï¼ˆå«å™ªå£°ï¼‰æ¨¡å‹"""
        print("ğŸš€ è®­ç»ƒåŸå§‹ï¼ˆå«å™ªå£°ï¼‰æ¨¡å‹...")
        
        try:
            # åˆ›å»ºæ¨¡å‹
            original_model = self.bert_trainer.create_model()
            
            # ä¿å­˜åˆå§‹çŠ¶æ€ç”¨äºåç»­ç›¸åŒåˆå§‹åŒ–
            initial_state = self.bert_trainer.save_model_state(original_model)
            
            # è®­ç»ƒæ¨¡å‹
            training_history = self.bert_trainer.train_model(
                model=original_model,
                data=data,
                epochs=self.config['epochs'],
                batch_size=self.config['batch_size'],
                learning_rate=self.config['learning_rate']
            )
            
            # ä¿å­˜è®­ç»ƒå†å²
            self.bert_trainer.save_training_history(
                training_history, 
                str(self.output_dir / "original_training")
            )
            
            # ä¿å­˜ç»“æœ
            self.results['original_training'] = {
                'history': training_history,
                'model_path': str(self.output_dir / "original_model.pt"),
                'initial_state_path': str(self.output_dir / "initial_state.pt")
            }
            
            # ä¿å­˜æ¨¡å‹å’Œåˆå§‹çŠ¶æ€
            torch.save(original_model.state_dict(), self.output_dir / "original_model.pt")
            torch.save(initial_state, self.output_dir / "initial_state.pt")
            
            print("âœ… åŸå§‹æ¨¡å‹è®­ç»ƒå®Œæˆ")
            
            return original_model, initial_state, training_history
            
        except Exception as e:
            error_msg = f"åŸå§‹æ¨¡å‹è®­ç»ƒå¤±è´¥: {e}"
            print(f"âŒ {error_msg}")
            self.results['error_log'].append(error_msg)
            raise
            
    def compute_influence_scores(self, model, data: Dict) -> np.ndarray:
        """è®¡ç®—TIMå½±å“åŠ›åˆ†æ•°"""
        print("ğŸ“Š è®¡ç®—TIMå½±å“åŠ›åˆ†æ•°...")
        
        try:
            # è®¡ç®—å½±å“åŠ›
            influence_scores = self.tim_calculator.compute_influence(model, data)
            
            # åˆ†æå½±å“åŠ›åˆ†æ•°
            noise_indices = self.data_processor.noise_indices
            analysis = self.tim_calculator.analyze_influence_scores(
                influence_scores, 
                data['y_train'], 
                noise_indices
            )
            
            # ä¿å­˜å½±å“åŠ›ç»“æœ
            self.tim_calculator.save_influence_results(
                influence_scores, 
                analysis, 
                str(self.output_dir / "influence_analysis")
            )
            
            # ä¿å­˜ç»“æœ
            self.results['influence_analysis'] = {
                'scores': influence_scores.tolist(),
                'statistics': analysis,
                'save_path': str(self.output_dir / "influence_analysis")
            }
            
            print("âœ… å½±å“åŠ›è®¡ç®—å®Œæˆ")
            
            return influence_scores, analysis
            
        except Exception as e:
            error_msg = f"å½±å“åŠ›è®¡ç®—å¤±è´¥: {e}"
            print(f"âŒ {error_msg}")
            self.results['error_log'].append(error_msg)
            raise
            
    def prune_data(self, influence_scores: np.ndarray, original_data: Dict) -> Dict:
        """æ ¹æ®å½±å“åŠ›åˆ†æ•°å‰ªææ•°æ®"""
        print("âœ‚ï¸  æ ¹æ®å½±å“åŠ›å‰ªææ•°æ®...")
        
        try:
            # é€‰æ‹©è¦å‰ªæçš„æ ·æœ¬
            prune_indices, keep_indices = self.tim_calculator.select_bottom_k_samples(
                influence_scores, 
                k_ratio=self.config['prune_ratio']
            )
            
            # æ‰§è¡Œæ•°æ®å‰ªæ
            pruned_data, remaining_indices = self.data_processor.prune_data_by_indices(prune_indices)
            
            # ä¿å­˜å‰ªææ•°æ®
            self.data_processor.save_data(pruned_data, str(self.output_dir / "pruned_data"))
            
            # åˆ†æå‰ªææ•ˆæœ
            noise_indices = self.data_processor.noise_indices
            pruned_noise = np.intersect1d(prune_indices, noise_indices)
            noise_recall = len(pruned_noise) / len(noise_indices) if len(noise_indices) > 0 else 0
            noise_precision = len(pruned_noise) / len(prune_indices) if len(prune_indices) > 0 else 0
            
            pruning_analysis = {
                'prune_indices': prune_indices.tolist(),
                'keep_indices': keep_indices.tolist(),
                'remaining_indices': remaining_indices.tolist(),
                'original_samples': len(original_data['y_train']),
                'pruned_samples': len(prune_indices),
                'remaining_samples': len(remaining_indices),
                'prune_ratio': len(prune_indices) / len(original_data['y_train']),
                'noise_detection': {
                    'total_noise': len(noise_indices),
                    'captured_noise': len(pruned_noise),
                    'noise_recall': noise_recall,
                    'noise_precision': noise_precision
                }
            }
            
            # ä¿å­˜ç»“æœ
            self.results['pruning_analysis'] = pruning_analysis
            
            print("âœ… æ•°æ®å‰ªæå®Œæˆ")
            print(f"   å‰ªææ ·æœ¬: {len(prune_indices)} ({len(prune_indices)/len(original_data['y_train'])*100:.1f}%)")
            print(f"   å™ªå£°æ•è·: {len(pruned_noise)}/{len(noise_indices)} (å¬å›ç‡: {noise_recall:.2%})")
            
            return pruned_data, prune_indices, keep_indices
            
        except Exception as e:
            error_msg = f"æ•°æ®å‰ªæå¤±è´¥: {e}"
            print(f"âŒ {error_msg}")
            self.results['error_log'].append(error_msg)
            raise
            
    def train_pruned_model(self, pruned_data: Dict, initial_state: Dict) -> Dict:
        """ç”¨ç›¸åŒåˆå§‹åŒ–è®­ç»ƒå‰ªæåçš„æ¨¡å‹"""
        print("ğŸš€ è®­ç»ƒå‰ªæåæ¨¡å‹ï¼ˆç›¸åŒåˆå§‹åŒ–ï¼‰...")
        
        try:
            # åˆ›å»ºæ–°æ¨¡å‹å¹¶åŠ è½½ç›¸åŒçš„åˆå§‹çŠ¶æ€
            pruned_model = self.bert_trainer.create_model()
            pruned_model = self.bert_trainer.load_model_state(pruned_model, initial_state)
            
            # è®­ç»ƒæ¨¡å‹
            pruned_history = self.bert_trainer.train_model(
                model=pruned_model,
                data=pruned_data,
                epochs=self.config['epochs'],
                batch_size=self.config['batch_size'],
                learning_rate=self.config['learning_rate']
            )
            
            # ä¿å­˜è®­ç»ƒå†å²
            self.bert_trainer.save_training_history(
                pruned_history,
                str(self.output_dir / "pruned_training")
            )
            
            # ä¿å­˜ç»“æœ
            self.results['pruned_training'] = {
                'history': pruned_history,
                'model_path': str(self.output_dir / "pruned_model.pt")
            }
            
            # ä¿å­˜æ¨¡å‹
            torch.save(pruned_model.state_dict(), self.output_dir / "pruned_model.pt")
            
            print("âœ… å‰ªæåæ¨¡å‹è®­ç»ƒå®Œæˆ")
            
            return pruned_model, pruned_history
            
        except Exception as e:
            error_msg = f"å‰ªæåæ¨¡å‹è®­ç»ƒå¤±è´¥: {e}"
            print(f"âŒ {error_msg}")
            self.results['error_log'].append(error_msg)
            raise
            
    def create_visualizations(
        self,
        original_history: Dict,
        pruned_history: Dict,
        influence_scores: np.ndarray,
        influence_analysis: Dict,
        prune_indices: np.ndarray,
        keep_indices: np.ndarray
    ):
        """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
        if not self.config['save_plots'] or self.visualizer is None:
            print("â­ï¸  è·³è¿‡å¯è§†åŒ–ï¼ˆsave_plots=Falseï¼‰")
            return
            
        print("ğŸ¨ åˆ›å»ºå¯è§†åŒ–å›¾è¡¨...")
        
        try:
            noise_indices = self.data_processor.noise_indices
            
            # 1. åŸå§‹è®­ç»ƒæ›²çº¿
            self.visualizer.plot_training_curves(
                original_history,
                title="åŸå§‹ï¼ˆå«å™ªå£°ï¼‰è®­ç»ƒæ›²çº¿",
                save_name="original_training_curves.png"
            )
            
            # 2. å‰ªæåè®­ç»ƒæ›²çº¿
            self.visualizer.plot_training_curves(
                pruned_history,
                title="å‰ªæåè®­ç»ƒæ›²çº¿", 
                save_name="pruned_training_curves.png"
            )
            
            # 3. å½±å“åŠ›åˆ†å¸ƒ
            self.visualizer.plot_influence_distribution(
                influence_scores,
                noise_indices,
                title="TIMå½±å“åŠ›åˆ†æ•°åˆ†å¸ƒ",
                save_name="influence_distribution.png"
            )
            
            # 4. å‰ªæåˆ†æ
            self.visualizer.plot_pruning_analysis(
                influence_scores,
                prune_indices,
                keep_indices,
                noise_indices,
                title="æ•°æ®å‰ªæåˆ†æ",
                save_name="pruning_analysis.png"
            )
            
            # 5. å¯¹æ¯”åˆ†æ
            self.visualizer.plot_comparative_analysis(
                original_history,
                pruned_history,
                influence_analysis,
                title="å‰ªæå‰åå¯¹æ¯”åˆ†æ",
                save_name="comparative_analysis.png"
            )
            
            print("âœ… å¯è§†åŒ–å›¾è¡¨åˆ›å»ºå®Œæˆ")
            
        except Exception as e:
            error_msg = f"å¯è§†åŒ–åˆ›å»ºå¤±è´¥: {e}"
            print(f"âš ï¸  {error_msg}")
            self.results['error_log'].append(error_msg)
            
    def run_complete_experiment(self) -> Dict:
        """è¿è¡Œå®Œæ•´çš„å™ªå£°å‰ªæå®éªŒ"""
        print("ğŸ§ª å¼€å§‹å®Œæ•´çš„å™ªå£°å‰ªæå®éªŒ")
        print("=" * 60)
        
        self.results['start_time'] = time.time()
        self.results['status'] = 'running'
        
        try:
            # 1. è®¾ç½®ç»„ä»¶
            self.setup_components()
            
            # 2. å‡†å¤‡æ•°æ®
            noisy_data, noise_indices = self.prepare_data()
            
            # 3. è®­ç»ƒåŸå§‹æ¨¡å‹
            original_model, initial_state, original_history = self.train_original_model(noisy_data)
            
            # 4. è®¡ç®—å½±å“åŠ›åˆ†æ•°
            influence_scores, influence_analysis = self.compute_influence_scores(original_model, noisy_data)
            
            # 5. å‰ªææ•°æ®
            pruned_data, prune_indices, keep_indices = self.prune_data(influence_scores, noisy_data)
            
            # 6. è®­ç»ƒå‰ªæåæ¨¡å‹
            pruned_model, pruned_history = self.train_pruned_model(pruned_data, initial_state)
            
            # 7. åˆ›å»ºå¯è§†åŒ–
            self.create_visualizations(
                original_history, pruned_history, influence_scores, 
                influence_analysis, prune_indices, keep_indices
            )
            
            # 8. ç”Ÿæˆå¯¹æ¯”åˆ†æ
            self.generate_comparative_analysis(original_history, pruned_history)
            
            # 9. ä¿å­˜å®éªŒç»“æœ
            self.save_experiment_results()
            
            self.results['status'] = 'success'
            self.results['end_time'] = time.time()
            
            print("ğŸ‰ å®éªŒå®Œæˆï¼")
            self.print_experiment_summary()
            
            return self.results
            
        except Exception as e:
            self.results['status'] = 'failed'
            self.results['end_time'] = time.time()
            error_msg = f"å®éªŒå¤±è´¥: {e}"
            print(f"ğŸ’¥ {error_msg}")
            self.results['error_log'].append(error_msg)
            traceback.print_exc()
            return self.results
            
    def generate_comparative_analysis(self, original_history: Dict, pruned_history: Dict):
        """ç”Ÿæˆå¯¹æ¯”åˆ†æç»“æœ"""
        print("ğŸ“ˆ ç”Ÿæˆå¯¹æ¯”åˆ†æ...")
        
        try:
            orig_final = original_history.get('final_performance', {})
            pruned_final = pruned_history.get('final_performance', {})
            
            comparative_analysis = {
                'performance_improvement': {
                    'train_accuracy': {
                        'original': orig_final.get('train_accuracy', 0),
                        'pruned': pruned_final.get('train_accuracy', 0),
                        'improvement': pruned_final.get('train_accuracy', 0) - orig_final.get('train_accuracy', 0)
                    },
                    'valid_accuracy': {
                        'original': orig_final.get('valid_accuracy', 0),
                        'pruned': pruned_final.get('valid_accuracy', 0),
                        'improvement': pruned_final.get('valid_accuracy', 0) - orig_final.get('valid_accuracy', 0)
                    },
                    'train_loss': {
                        'original': orig_final.get('train_loss', 0),
                        'pruned': pruned_final.get('train_loss', 0),
                        'improvement': orig_final.get('train_loss', 0) - pruned_final.get('train_loss', 0)  # æŸå¤±è¶Šä½è¶Šå¥½
                    }
                },
                'training_efficiency': {
                    'original_time': orig_final.get('total_time', 0),
                    'pruned_time': pruned_final.get('total_time', 0),
                    'time_saving': orig_final.get('total_time', 0) - pruned_final.get('total_time', 0)
                },
                'convergence_analysis': {
                    'original_final_epoch_loss': original_history.get('train_loss', [])[-1] if original_history.get('train_loss') else 0,
                    'pruned_final_epoch_loss': pruned_history.get('train_loss', [])[-1] if pruned_history.get('train_loss') else 0
                }
            }
            
            self.results['comparative_analysis'] = comparative_analysis
            
            print("âœ… å¯¹æ¯”åˆ†æç”Ÿæˆå®Œæˆ")
            
        except Exception as e:
            error_msg = f"å¯¹æ¯”åˆ†æç”Ÿæˆå¤±è´¥: {e}"
            print(f"âš ï¸  {error_msg}")
            self.results['error_log'].append(error_msg)
            
    def save_experiment_results(self):
        """ä¿å­˜å®Œæ•´çš„å®éªŒç»“æœ"""
        print("ğŸ’¾ ä¿å­˜å®éªŒç»“æœ...")
        
        try:
            # ä¿å­˜ä¸»ç»“æœæ–‡ä»¶
            with open(self.output_dir / "experiment_results.json", 'w', encoding='utf-8') as f:
                json.dump(self.results, f, indent=2, ensure_ascii=False, default=str)
                
            # ä¿å­˜é…ç½®æ–‡ä»¶
            with open(self.output_dir / "experiment_config.json", 'w', encoding='utf-8') as f:
                json.dump(self.config, f, indent=2, ensure_ascii=False)
                
            print(f"âœ… å®éªŒç»“æœå·²ä¿å­˜åˆ°: {self.output_dir}")
            
        except Exception as e:
            error_msg = f"ç»“æœä¿å­˜å¤±è´¥: {e}"
            print(f"âš ï¸  {error_msg}")
            self.results['error_log'].append(error_msg)
            
    def print_experiment_summary(self):
        """æ‰“å°å®éªŒæ‘˜è¦"""
        print("\\n" + "=" * 60)
        print("ğŸ“Š å®éªŒæ‘˜è¦")
        print("=" * 60)
        
        # åŸºæœ¬ä¿¡æ¯
        print(f"ğŸ“ ç»“æœç›®å½•: {self.output_dir}")
        print(f"â±ï¸  æ€»è€—æ—¶: {self.results.get('end_time', 0) - self.results.get('start_time', 0):.1f}ç§’")
        print(f"ğŸ¯ å®éªŒçŠ¶æ€: {self.results.get('status', 'unknown')}")
        
        # æ•°æ®ä¿¡æ¯
        data_stats = self.results.get('data_stats', {})
        if data_stats:
            noise_info = data_stats.get('noise_info', {})
            print(f"\\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
            print(f"   è®­ç»ƒæ ·æœ¬: {noise_info.get('total_samples', 'N/A')}")
            print(f"   å™ªå£°æ ·æœ¬: {noise_info.get('noise_count', 'N/A')} ({noise_info.get('noise_rate', 0)*100:.1f}%)")
        
        # æ€§èƒ½å¯¹æ¯”
        comparative = self.results.get('comparative_analysis', {})
        if comparative:
            perf = comparative.get('performance_improvement', {})
            print(f"\\nğŸš€ æ€§èƒ½æ”¹è¿›:")
            
            train_acc = perf.get('train_accuracy', {})
            print(f"   è®­ç»ƒå‡†ç¡®ç‡: {train_acc.get('original', 0):.3f} â†’ {train_acc.get('pruned', 0):.3f} ({train_acc.get('improvement', 0):+.3f})")
            
            valid_acc = perf.get('valid_accuracy', {})
            print(f"   éªŒè¯å‡†ç¡®ç‡: {valid_acc.get('original', 0):.3f} â†’ {valid_acc.get('pruned', 0):.3f} ({valid_acc.get('improvement', 0):+.3f})")
            
            train_loss = perf.get('train_loss', {})
            print(f"   è®­ç»ƒæŸå¤±: {train_loss.get('original', 0):.3f} â†’ {train_loss.get('pruned', 0):.3f} ({train_loss.get('improvement', 0):+.3f})")
        
        # å™ªå£°æ£€æµ‹æ•ˆæœ
        pruning = self.results.get('pruning_analysis', {})
        if pruning:
            noise_det = pruning.get('noise_detection', {})
            print(f"\\nğŸ” å™ªå£°æ£€æµ‹æ•ˆæœ:")
            print(f"   å™ªå£°å¬å›ç‡: {noise_det.get('noise_recall', 0)*100:.1f}%")
            print(f"   å‰ªæç²¾ç¡®ç‡: {noise_det.get('noise_precision', 0)*100:.1f}%")
        
        # é”™è¯¯æ—¥å¿—
        if self.results.get('error_log'):
            print(f"\\nâš ï¸  é”™è¯¯æ—¥å¿—:")
            for error in self.results['error_log']:
                print(f"   â€¢ {error}")
        
        print("=" * 60)


def create_experiment(
    # Data configuration
    dataset_name: str = "imdb",
    train_count: int = 5000,  # Large-scale data for server
    valid_count: int = 1000,
    test_count: int = 1000,
    noise_rate: float = 0.3,
    
    # Model configuration
    model_name: str = "distilbert-base-uncased", 
    
    # Training configuration
    epochs: int = 10,  # More epochs for better convergence
    batch_size: int = 32,  # Larger batch size for server
    
    # TIM configuration
    tim_epochs: int = 5,  # More TIM epochs for better influence computation
    
    # Experiment configuration
    output_dir: str = "./large_scale_noise_pruning_results",
    random_state: int = 42
) -> NoisePruningExperiment:
    """
    Factory function: Create noise pruning experiment
    
    Parameters:
    -----------
    dataset_name : str
        Dataset name, default "imdb"
    train_count : int
        Training sample count, default 5000
    valid_count : int
        Validation sample count, default 1000
    test_count : int
        Test sample count, default 1000
    noise_rate : float
        Noise ratio, default 0.3
    model_name : str
        Model name, default "distilbert-base-uncased"
    epochs : int
        Training epochs, default 10
    batch_size : int
        Batch size, default 32
    tim_epochs : int
        TIM epochs, default 5
    output_dir : str
        Output directory, default "./large_scale_noise_pruning_results"
    random_state : int
        Random seed, default 42
        
    Returns:
    --------
    NoisePruningExperiment
        Configured experiment object
    """
    return NoisePruningExperiment(
        dataset_name=dataset_name,
        train_count=train_count,
        valid_count=valid_count,
        test_count=test_count,
        noise_rate=noise_rate,
        model_name=model_name,
        epochs=epochs,
        batch_size=batch_size,
        tim_epochs=tim_epochs,
        output_dir=output_dir,
        random_state=random_state
    )


def main():
    """Main function - Run complete large-scale experiment"""
    print("ğŸ§ª Large-scale Noise Data Pruning Experiment")
    print("=" * 60)
    
    # Create large-scale experiment with default parameters optimized for server
    experiment = create_experiment()  # Uses large-scale defaults
    
    # Run experiment
    results = experiment.run_complete_experiment()
    
    # Return results
    return results


if __name__ == "__main__":
    success = main()
    if success and success.get('status') == 'success':
        print("\\nğŸ‰ å®éªŒæˆåŠŸå®Œæˆï¼")
        sys.exit(0)
    else:
        print("\\nâŒ å®éªŒå¤±è´¥")
        sys.exit(1)